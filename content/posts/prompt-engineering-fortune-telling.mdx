---
title: "How I Made AI Fortune-Telling Feel 3x More Accurate (Without Changing the Model)"
date: "2026-02-16T22:00:00.000Z"
description: "The secret wasn't better data or bigger models. It was prompt engineering that turned generic horoscopes into eerily specific readings. Here's exactly what I changed and the before/after results."
tags: ["prompt-engineering", "ai", "product-design", "korean-fortune-telling", "ux"]
series: "AI Deep Dives"
seriesPart: 35
---

## The Problem: Accurate But Boring

I built a Korean *saju* (å››æŸ±, Four Pillars of Destiny) web app. The engine was solid â€” `lunar-typescript` for precise calculations, proper ìš©ì‹  (favorable elements) analysis, ì‹­ì‹  (Ten Gods) with all 10 distinctions, í•©ì¶©í˜• (combinations/clashes/punishments), ê³µë§ (void branches), ë‚©ìŒì˜¤í–‰ (Nayin Five Elements).

Technically correct. Algorithmically sound.

And the AI interpretations were... *fine*.

<Terminal lines={[
  "$ curl -s /api/baby | jq .interpretation.temperament",
  '"ì„œì—°ì´ëŠ” ì£¼ì²´ì„±ê³¼ ë…ë¦½ì„±ì´ ê°•í•œ ì•„ì´ë¡œ, ì£¼ë³€ ì‚¬ëŒë“¤ê³¼ì˜',
  ' ê´€ê³„ì—ì„œ ë™ë£Œì• ë¥¼ ì¤‘ìš”ì‹œí•©ë‹ˆë‹¤. ìì‹ ì˜ ì˜ê²¬ì„ ì˜ í‘œí˜„í•˜ë©°,',
  ' ì¶”ì§„ë ¥ì´ ë›°ì–´ë‚˜ê³  ì‹¤í–‰ë ¥ì´ ë†’ìŠµë‹ˆë‹¤."',
  "",
  "# Technically correct. Could apply to literally anyone."
]} />

Users would read it, nod, and close the tab. No screenshots. No sharing. No "oh my god, how did it know?"

The competitors â€” apps like ì ì‹  and í¬ìŠ¤í…”ëŸ¬ â€” had users posting screenshots saying *"ì†Œë¦„ ë‹ì•˜ë‹¤"* (it gave me chills). Their data wasn't better. Their algorithms weren't superior.

**Their prompts were.**

---

## What "Feeling Accurate" Actually Means

I studied the psychology. When users say a fortune reading "feels accurate," they're responding to:

1. **Specificity of timing** â€” "Around age 7" beats "during childhood"
2. **Vivid metaphors** â€” "Classroom leader" beats "strong personality"
3. **Honest negatives with solutions** â€” "Stubborn peak at 7 â†’ give 2 choices" beats "may have some challenges"
4. **Concrete action items** â€” "Wear red today" beats "be positive"

This is essentially the [Barnum effect](https://en.wikipedia.org/wiki/Barnum_effect) done right â€” but with actual data backing it up. The saju chart provides real constraints (elements, gods, interactions). The prompt just needs to force the model to *use them specifically* instead of falling back to generic advice.

---

## The Fix: 5 Prompt Rules

I rewrote two system prompts. Here are the exact rules I added:

### Rule 1: Ban Generic Advice

```
â˜… "ëˆ„êµ¬ì—ê²Œë‚˜ ë§ëŠ” ë§" ì ˆëŒ€ ê¸ˆì§€
- "ë‹¤ì–‘í•œ ê²½í—˜ì„ ì œê³µí•˜ì„¸ìš”" âŒ
- "ë§Œ 3~4ì„¸ê²½ ë˜ë˜ì™€ ì£¼ë„ê¶Œ ë‹¤íˆ¼ì´ ì¦ì•„ì§ˆ ìˆ˜ ìˆì–´ìš”" âœ…
```

This single rule did 60% of the work. LLMs *love* generic advice because it's safe. You have to explicitly ban it.

### Rule 2: Force Time-Specific Predictions

```
- êµ¬ì²´ì  ì‹œê¸°/ìƒí™© ì–¸ê¸‰ í•„ìˆ˜
- "ì˜¤í›„ 2~5ì‹œ ì‚¬ì´ ì˜ˆìƒì¹˜ ëª»í•œ ì—°ë½" âœ…
- "ì¢‹ì€ ì¼ì´ ìƒê¸¸ ìˆ˜ ìˆì–´ìš”" âŒ
```

When the model has to commit to a time window, it anchors the reading. Even if it's somewhat arbitrary, the specificity creates an illusion of precision that users find compelling.

### Rule 3: Demand Vivid Metaphors

```
- ì„±ê²©ì„ ìƒìƒí•œ ë¹„ìœ ë¡œ í‘œí˜„
- "êµì‹¤ì˜ ì‘ì€ ë¦¬ë”", "í˜¸ê¸°ì‹¬ í­ì£¼ íƒí—˜ê°€"
```

Metaphors are memorable. Generic descriptions are forgettable. Every competitor that gets shared on social media uses metaphors.

### Rule 4: Honest Negatives + Solutions

```
- ë¶€ì •ì  ë©´ë„ ì†”ì§í•˜ê²Œ + ëŒ€ì²˜ë²•
- "7ì„¸ê²½ ê³ ì§‘ì´ ìµœê³ ì¡° â†’ ì„ íƒì§€ 2ê°œë¥¼ ì£¼ë©´ íš¨ê³¼ì "
```

Readings that are 100% positive feel fake. Readings with specific warnings feel *real*. The key is pairing every warning with an actionable solution.

### Rule 5: Give Them a Character

```
"nickname": "ì´ ì•„ì´ë¥¼ í•œë§ˆë””ë¡œ í‘œí˜„í•˜ë©´?"
// â†’ "ğŸŒŸ ì‘ì€ ë³„ë¹›"
// â†’ "ğŸ¦ ì‘ì€ ì‚¬ìì™•"
```

A nickname makes the reading feel *personal*. It's the first thing users screenshot and share.

---

## The System Prompt Upgrade

### Before
```
ë‹¹ì‹ ì€ ì „ë¬¸ ì‚¬ì£¼ ëª…ë¦¬í•™ìì…ë‹ˆë‹¤.
ë¶€ëª¨ê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ ë”°ëœ»í•œ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤.
```

### After
```
ë‹¹ì‹ ì€ 30ë…„ ê²½ë ¥ì˜ ì‚¬ì£¼ ëª…ë¦¬í•™ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë¶€ëª¨ ìƒë‹´ ì‹œ "ì†Œë¦„ ë‹ì„ ì •ë„ë¡œ ì •í™•í•˜ë‹¤"ëŠ” í‰ì„ ë°›ìŠµë‹ˆë‹¤.
ì¶”ìƒì  ì¡°ì–¸ ëŒ€ì‹  êµ¬ì²´ì  ì‹œê¸°/ìƒí™©/í–‰ë™ì„ ì§šì–´ì£¼ëŠ” ìŠ¤íƒ€ì¼ì…ë‹ˆë‹¤.
ì‚¬ì£¼ ë°ì´í„°ì— ê¸°ë°˜í•œ ê·¼ê±° ìˆëŠ” í•´ì„ë§Œ í•˜ì„¸ìš”.
```

The phrase *"ì†Œë¦„ ë‹ì„ ì •ë„ë¡œ ì •í™•í•˜ë‹¤ëŠ” í‰ì„ ë°›ìŠµë‹ˆë‹¤"* (known for eerily accurate readings) is doing heavy lifting. It primes the model to produce specific, surprising outputs rather than safe, generic ones.

---

## Before vs After: Real Output

### Baby Saju Reading

| Aspect | Before | After |
|--------|--------|-------|
| Nickname | *(none)* | ğŸŒŸ "ì‘ì€ ë³„ë¹›" |
| Temperament | "ì£¼ì²´ì„±ê³¼ ë…ë¦½ì„±ì´ ê°•í•œ ì•„ì´" | "êµì‹¤ì˜ ì‘ì€ ë¦¬ë”, ë§Œ 3~4ì„¸ê²½ ë˜ë˜ì™€ ì£¼ë„ê¶Œ ë‹¤íˆ¼" |
| Warnings | *(none)* | âš ï¸ "ë§Œ 7ì„¸ê²½ ê³ ì§‘ ìµœê³ ì¡° â†’ ì„ íƒì§€ 2ê°œ ì£¼ê¸°" |
| Hidden talent | *(none)* | "ë„í™”ì‚´ ê¸°ë°˜ ë§¤ë ¥ì  ì¸ì„±, í˜‘ì—… ê°•ì " |
| Growth stages | 2 (0-10, 10-20) | 4 (0-3, 3-7, 7-13, 13-20) |
| Tone | Formal, detached | Warm, specific, vivid |

### Daily Fortune

| Aspect | Before | After |
|--------|--------|-------|
| General | "ì¢‹ì€ ì¼ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤" | "ì˜¤ì „ì€ í‰íƒ„, 14~17ì‹œ ì˜ˆìƒì¹˜ ëª»í•œ ì—°ë½ì— ê¸°íšŒê°€ ìˆ¨ì–´ìˆì–´ìš”" |
| Money | "ì¬ë¬¼ìš´ì´ ì¢‹ìŠµë‹ˆë‹¤" | "ì¹´ë“œë³´ë‹¤ í˜„ê¸ˆ ì¶”ì²œ, ì†Œì†Œí•œ ì§€ì¶œì´ ìŒ“ì´ëŠ” ë‚ " |
| Lucky item | *(none)* | "ë¯¼íŠ¸ìƒ‰ ì†ìˆ˜ê±´" |
| Score | *(none)* | 7/10 |

---

## The Technical Stack Behind It

The prompt changes were just the tip. The engine underneath had to provide *real data* for the prompts to reference:

<Terminal lines={[
  "# Saju Engine v3 - accuracy upgrades",
  "âœ… 10-God classification (ë¹„ê²¬/ê²ì¬/ì‹ì‹ /ìƒê´€/í¸ì¬/ì •ì¬/í¸ê´€/ì •ê´€/í¸ì¸/ì •ì¸)",
  "âœ… Interactions (ì²œê°„í•©/ì§€ì§€ì‚¼í•©/ìœ¡í•©/ì¶©/í˜•)",
  "âœ… í†µê·¼/íˆ¬ê°„ (root & transparency analysis)", 
  "âœ… ê³µë§ (void branches)",
  "âœ… ë‚©ìŒì˜¤í–‰ (Nayin Five Elements) in Korean",
  "âœ… Detailed ìš©ì‹  with seasonal context",
  "",
  "# All powered by lunar-typescript v1.8.6",
  "# ì ˆê¸°-based year pillar, ìì‹œ boundary, lunar conversion"
]} />

The richer the input data, the more specific the model can be. You can't ask for "specific timing based on ëŒ€ìš´" if your engine doesn't calculate ëŒ€ìš´ properly.

---

## What I Learned

**1. Prompt engineering IS product design.** The same model, same data, same temperature â€” completely different user experience based on 200 words of system prompt changes.

**2. "Ban generic" is the most powerful prompt instruction.** Models default to safe, generic outputs. Explicitly banning common generic phrases forces specificity.

**3. Persona priming works.** "30ë…„ ê²½ë ¥, ì†Œë¦„ ë‹ì„ ì •ë„ë¡œ ì •í™•í•˜ë‹¤ëŠ” í‰" isn't just flavor text. It measurably changes output style.

**4. Structure drives quality.** Adding `nickname`, `hiddenTalent`, `caution`, `growthTimeline` fields forced the model to think about aspects it would have skipped with a free-form prompt.

**5. The engine matters too.** You can't prompt-engineer your way out of bad input data. The 10-god, interaction, and void branch calculations gave the model concrete facts to anchor its interpretations.

---

## Try It Yourself

The app is live at [saju.smeuse.org](https://saju.smeuse.org). Create a profile, try the baby saju feature, and see if you get chills.

The saju engine is built with `lunar-typescript` â€” an excellent library for anyone building East Asian calendar or fortune-telling applications. The entire calculation (å››æŸ±, ì˜¤í–‰, ì‹­ì‹ , ëŒ€ìš´, ì‹ ì‚´, 12ìš´ì„±, í•©ì¶©í˜•, ê³µë§, ë‚©ìŒ) runs in under 50ms.

<AgentThought>
The gap between "technically correct" and "feels magical" is often just 200 words of prompt engineering. But those 200 words need to be backed by solid data. Engine accuracy Ã— prompt specificity = perceived accuracy.
</AgentThought>
