---
title: "AGENTS.md: 6만 개 프로젝트가 채택한 한 파일의 힘과 함정"
date: "2026-02-28T11:30:00.000Z"
description: "AGENTS.md는 AAIF(리눅스재단 산하) 관리 하에 6만 개 이상 프로젝트에 채택되었지만, ETH 취리히 연구는 성능 저하와 비용 증가를 보고했습니다. 효과적인 작성 원칙을 정리해 한국 독자 맞춤으로 실제 운영 지침을 제안합니다."
tags: ["AGENTS.md", "AI Agents", "Developer Tools", "Best Practices"]
coverImage: /images/default-cover.jpg
---

처음 AGENTS.md를 만나고 난 뒤로, 나는 코드베이스의 AI 협업 습관을 완전히 바꾸어야겠다고 생각한 적이 몇 번 있다.

특히 리포지토리 루트에 `AGENTS.md` 하나를 두고, “에이전트가 이 프로젝트를 더 잘 이해하게 하자”는 생각이 무척 매력적이었다. 실제로 처음엔 효과가 확실해 보였다. 빌드/테스트/커맨드 규칙을 한 번에 정리해 두고, AI에게 작업할 때마다 같은 맥락을 반복해서 설명할 필요가 줄어드는 느낌이었다.

그런데 어느 순간, 성능 리포트를 들춰보던 중 3% 하락, 비용 20% 증가라는 수치가 눈에 들어왔다. **ETH 취리히 연구팀의 실험은, AGENTS.md가 늘 정답이 아니라는 점을 아주 냉혹하게 보여줬다.**

그 순간부터 나는 이 주제를 “채택 수치냐, 실제 성능이냐”로 나누어 보기 시작했다.

이번 글은 내 입장에서 정리한 판단 프레임이다.

- 먼저, AGENTS.md가 왜 60,000개 이상의 저장소 채택까지 갔는지,
- 왜 이 파일이 오히려 오버헤드를 만들 수 있는지,
- 그리고 GitHub의 2,500개 레포 분석이 말하는 ‘잘 쓰는 방식’이 무엇인지.

---

## 1) AGENTS.md는 왜 지금 뜨는가: 채택의 스케일이 보여주는 구조적 이유

공식 채널을 보면 이 파일의 출발점은 단순한 편의 기능이 아니라, 운영 전략이었다.

[OpenAI의 AAIF 블로그 기고](https://openai.com/ko-KR/index/agentic-ai-foundation/)와 [AGENTS.md 공식 페이지](https://agents.md/)를 보면, AGENTS.md는 코드 에이전트가 저장소별 규칙을 예측 가능하게 읽을 수 있게 만들려는 목적이 핵심이었다.

핵심 문장을 요약하면 이렇다.

- README는 사람을 위한 문서,
- AGENTS.md는 에이전트를 위한 문서,
- 한 파일로 실행 명령, 테스트 규칙, 금지 영역 등을 명시해 다중 에이전트와 도구 체인에서 일관된 동작을 얻자.

그래서 AAIF(Agentic AI Foundation)에 이 포맷을 기부한 구조는 우연이 아니고, 사실상 **중립적 거버넌스 아래 호환성 확보를 위한 산업 설계**였다.

AAIF 쪽 페이지(https://aaif.io/)를 보면 모델 컨텍스트 프로토콜(MCP), goose, AGENTS.md 같은 자산이 함께 관리되고 있고, 구글/오픈AI/앤트로픽/블록 등 초기 동참 축은 이미 생태계 파편화를 줄이는 방향으로 해석된다.

나는 이 포인트를 중요하게 본다. 여기서 AGENTS.md의 본질은 “한 팀이 자기 편의로 작성한 파일”이 아니라, **여러 툴과 벤더가 같이 읽을 수 있는 규약**로의 진화다.

---

## 2) 6만 개가 넘는 채택: 숫자가 말해주는 기대감

[AGENTS.md 공식 문서](https://agents.md/)에는 GitHub 검색 기준 60,000개 이상의 오픈소스 프로젝트 채택이라는 수치가 반복적으로 등장한다.

이 숫자는 단순히 “많이 쓰인다”는 게 아니라 다음을 뜻한다.

- 코더들이 문서 분리를 의식했다.
- 팀이 README로는 다 담기 어려운 실행 맥락이 필요하다고 느꼈다.
- 단일 에이전트가 아닌 멀티 에이전트 환경(코드 생성, 테스트, 문서화, 린트)에서 동일 규격이 도움이 된다는 체감이 생겼다.

그뿐 아니라 지원 에이전트는 20개 이상으로 늘어났다(공식 문서와 관련 자료 정리 기준).

내가 실제로 프로젝트를 볼 때, 모노레포에서 루트 AGENTS.md + 하위 디렉토리별 AGENTS.md 조합이 꽤 흔한 패턴이다. “상위 파일은 전체 정책, 하위 파일은 특화 규칙”이라는 계층이 분명히 작동한다.

여기서 오해하지 말아야 할 부분이 있다. **채택이 곧 효과 보장은 아니다.**

채택은 “필요를 느끼는 사람 수”의 증거이지, “그 방식이 항상 정답이다”의 증거는 아니다.

---

## 3) ETH 취리히 논문이 던진 불편한 질문: 정말 성능이 오르나?

[arXiv의 논문](https://arxiv.org/abs/2602.11988)은 꽤 분명하게 실험을 설계했다.

비교한 조건은 세 가지로 나뉜다.

1. 컨텍스트 파일 없음
2. LLM 생성 AGENTS.md 사용
3. 사람이 직접 작성한 AGENTS.md 사용

그리고 평가 집합으로 SWE-bench 계열 태스크와 AGENTbench를 함께 사용했다.

결과가 던진 메시지는 다음과 비슷하다.

- AI 생성 AGENTS.md는 성공률 저하(약 -3% 근처) 경향,
- 비용은 대체로 +20% 이상 증가,
- 사람 작성 파일도 향상은 미미하거나 소폭(+4%) 수준,
- 오버헤드(추가 단계, 추가 탐색)는 여전히 커짐.

이 수치가 나를 가장 강하게 건드린 건 **비용 곡선**이었다. 단순히 성공률만 본다면 “조금 떨어졌네”로도 끝낼 수 있는데, 실제 운영에서는 추론 단계가 늘어나면 API 비용, 응답시간, 대화 길이, 검토 비용이 모두 올라간다.

즉, AGENTS.md의 장점은 “에이전트가 덜 헤매게 만들 가능성”이고, 단점은 “에이전트가 더 많이 헤매게 만들 가능성”이다. 이 둘은 구현 품질에 의해 뒤바뀐다.

---

## 4) 왜 성능이 떨어질 수 있나: 내 기준의 3가지 해석

### 1) 지시 준수성이 과잉일 때

에이전트는 지시를 잘 따른다. 그래서 우리는 그것을 믿는다.

하지만 그 신뢰가 비용으로 바뀌는 순간이 있다.

- 문서에 **너무 자세한 금지 규칙**이 있으면,
- 에이전트는 그 규칙을 안전하게 지키려다 불필요한 탐색을 더 한다.

결과적으로 “필요한 패치”보다 “규칙 만족을 위한 추가 액션”이 늘어난다.

### 2) 중복 정보가 늘어남

README, CONTRIBUTING, docs, 위키까지 이미 잘 정리된 프로젝트에서 AGENTS.md가 같은 정보를 반복하면, 실제로는 중복 비용만 커진다.

에이전트 입장에서는 반복되는 규칙이 ‘중요 정보’처럼 보일 수 있어서 우선순위를 잡느라 시간을 쓴다.

### 3) 보편적 배경 지식의 반복

모델이 이미 갖고 있는 “React + Vite + TypeScript 표준 패턴” 같은 정보까지 반복하면 새로 배운 느낌이 안 난다.

결국 AGENTS.md가 정말로 도와주는 건 **예외 케이스**, **레거시 규칙**, **도구 특수성** 영역이다. 보편 규칙을 반복하면 오히려 신호 대 잡음비가 떨어진다.

이 부분은 GitHub가 말하는 “좋은 AGENTS.md”와 충돌하지 않는다. 오히려 연결된다. 즉, 명확하게 타깃팅한 규칙만 넣어야 한다.

---

## 5) GitHub의 반대편 데이터: 2,500개 분석이 가르쳐 준 ‘잘 쓴 파일’의 특징

[GitHub 블로그의 분석](https://github.blog/ai-and-ml/github-copilot/how-to-write-a-great-agents-md-lessons-from-over-2500-repositories/)은 흥미롭게도 반대 명제가 아니다.

거기서는 **실패한 파일과 성공한 파일이 구분되는 규칙**을 보여준다.

- **명령어를 앞부분에 배치**
- **코드 스니펫 중심**
- **명확한 경계선**(항상 해야 할 일/물어봐야 할 일/절대 금지)
- **정확한 스택 버전 명시**
- **테스트 전략과 git 워크플로우 포함**

그리고 가장 인상적인 건 `You are a helpful assistant` 같은 추상적 문장이 실패할 확률이 높고, `You are a [구체 역할] who handles [명시 범위]` 같은 문장이 더 나은 성공 패턴을 만든다는 점이다.

나는 이 결과를 “연구와 실무가 충돌한다”라고 볼 필요가 없다. 오히려 “실무 데이터는 ‘평균값’이 아니라 ‘설계 방식’의 차이를 드러낸다”로 본다.

---

## 6) 300줄 논쟁: 길이보다 핵심 밀도가 중요하다

ETH 쪽 논평과 커뮤니티 해설에서 300줄 또는 그 이하를 권하는 이야기가 반복된다. 나는 딱 하나로 정리한다.

**문서 길이는 길수록 유용하지 않다. 실행 빈도가 높은 규칙이 짧고 선명할수록 유용하다.**

나는 팀에 자주 말한다.

- AGENTS.md는 “정규직 규정집”이 아니라 “실행 규칙 카드”다.
- AGENTS.md는 프로젝트 역사 교과서가 아니다.
- AGENTS.md는 매 대화마다 모델 토큰 안으로 재로드되는 파일이다.

그리고 재활용되는 규칙인지, 매번 쓰레기처럼 스캔되는 규칙인지는 로그와 결과로 판별해야 한다.

예를 들어,

- `문서 1`에서 `어떤 테스트 프레임워크를 써야 하는지`가 이미 충분히 드러난다면,
- AGENTS.md에서 그것을 반복할 이유는 적다.

반대로

- 팀이 `uv`를 쓰는지 아니면 `pip` 기본을 쓰는지 분기되는 특수성,
- 특수 배포 단계,
- 규제 도메인에서의 금지 규칙

이런 건 반드시 적어야 한다.

---

## 7) 내 팀에서 유용한 AGENTS.md: 언제 써야 하나

내 실무 기준으로 AGENTS.md가 가장 잘 먹는 구간은 이렇다.

### 유용한 경우

1. **비표준 툴이 핵심인 팀**
   - `bun`을 기본 패키지 매니저로 쓰거나,
   - `uv`를 사용하거나,
   - 문서와 달리 실제 빌드/배포 커맨드가 특이한 경우

2. **모노레포/멀티패키지 구조**
   - 하위 모듈별 정책이 다르고,
   - 상향식 규칙 충돌을 줄여야 할 때

3. **규제 또는 보안 제약이 큰 조직**
   - DB 접근, 설정 편집, 시크릿 처리 같은 경계가 확실해야 할 때

4. **문서화가 허술한 레거시 코드베이스**
   - 신규 입문자도 문서를 읽어야 하지만, AI에도 최소한의 맥락이 필요한 경우

### AGENTS.md가 불필요한 경우

1. **매우 작은 프로젝트**
   - 파일 구조가 작고 패턴이 표준이면 오히려 오버헤드가 생김.

2. **문서가 과잉 정돈된 프로젝트**
   - 이미 테스트/빌드 규칙이 잘 잡힌 저장소는 중복.

3. **단일 에이전트 + 단일 도메인 업무**
   - 사람 프롬프트가 더 정교하고 가볍게 관리되는 경우가 많다.

---

## 8) 보안·거버넌스는 빼놓을 수 없다

이 글은 성능 위주이지만, 실제로는 보안이 더 먼저 올라온다.

AI가 읽는 파일은 곧 실행 권한의 일부가 된다.

내가 보고 있는 리스크는 두 가지.

- **프롬프트 인젝션**: 악성 지시가 들어가면 에이전트가 의도치 않은 동작 수행.
- **규칙 충돌**: 여러 레이어의 AGENTS가 충돌하면 상위 규칙이 기대와 다르게 적용.

그래서 문서가 길어지는 것보다 “통제 가능한 구조”가 더 중요하다.

권장:

- 루트 문서에 보안 경계만 단정하게 적는다.
- 시크릿·토큰·계정·내부 인프라 세부는 넣지 않는다.
- “ask first”가 필요한 변경은 명시한다.
- CI에서 AGENTS 기반 자동 실행이 있었으면 감사 로그를 남긴다.

AAIF 거버넌스에 올라갔다고 해도, 최종 신뢰 경로는 팀이 직접 관리해야 한다.

---

## 9) 내가 실제로 쓰는 작성 템플릿 (최소형)

나는 보통 다음 형태로 시작한다.

```markdown
---
name: test-agent
description: 단위 테스트와 회귀검증을 담당하는 에이전트
---

당신은 이 레포지토리의 테스트 책임자다.

## 핵심 명령
- 테스트 실행: `pytest -q --maxfail=1`
- 전체 테스트: `pytest`
- 린트: `ruff check .`

## 영역
- 수정 가능: `src/`, `tests/`
- 승인 필요: `pyproject.toml`, `poetry.lock`, `ci.yml`

## 경계
- ✅ Always: 테스트를 깨뜨리는 변경 없이 패치, 실패 케이스는 우선 재현
- ⚠️ Ask first: 새 의존성 추가, CI 규칙 변경
- 🚫 Never: 운영 비밀 또는 DB 커넥션 문자열 수정

## 결과물
- 변경 파일 목록 + 실패 원인 + 다음 테스트 제안 순으로 요약
```

이 템플릿은 길지 않다.

그리고 놀라운 건, 팀이 “짧고 구체적으로” 시작하면 실제로 협업 속도가 더 빨라진다는 점이다.

---

## 10) 영어권 분석과 한국팀 현실의 간극을 메우는 운영 규칙

영어권 커뮤니티에서 AGENTS.md는 종종 템플릿과 자동생성으로 빠르게 확산됐다. 한국 실무 환경에서는 아래처럼 다르게 적용해야 했다.

### A안: 프로젝트가 작고 빠르게 바뀌는 경우

- AGENTS.md는 최소 규칙 5개만 둔다.
- PR마다 규칙 변경이 필요하면 문서도 함께 갱신한다.
- 성능 저하 징후가 보이면 바로 줄인다.

### B안: 기존 문서가 넉넉한 경우

- AGENTS.md는 특수 파트를 한두 개만 정의한다.
- 대부분은 기존 docs/에 남겨서 관리, AGENTS.md에서는 포인터만 둔다.

### C안: 다중 에이전트 팀의 경우

- 에이전트별로 문서를 분리한다.
- `test-agent`, `docs-agent`처럼 역할 단위를 뚜렷하게 한다.
- 공통 규칙은 최소화하고, 각 역할 파일이 책임을 갖게 한다.

---

## 11) 결론: 나는 지금 AGENTS.md를 어떻게 본다

내 결론은 간단하다.

- AGENTS.md는 **죽은 포맷이 아니다**.
- AGENTS.md는 **만능 솔루션도 아니다**.
- AGENTS.md는 **제대로 설계하면 유용하지만, 잘못 쓰면 오히려 비용을 늘리는 장치**가 된다.

AAIF로 넘어간 덕분에 형식의 표준성은 확보됐다. ETH 취리히 연구는 과도한 맥락이 비용/성능에 미치는 손실을 보여줬다. GitHub 분석은 “어떤 규칙 구조가 먹히는지”를 정리해줬다.

가장 중요한 건 결국 내 손에 남는다.

> AGENTS.md를 쓸 때마다 나는 이렇게 묻는다.
>
> “이 줄이 없으면 에이전트가 더 잘못할 확률이 실제로 증가하나?”

답이 ‘아니오’면 지워 버린다.
답이 ‘예’일 때만 남긴다.

이게 내가 추구하는 **양날의 검** 관리법이다.

---

---

## 12) 내가 실제로 쓰는 4주 A/B 운영 체크리스트 (실무형)

숫자만 믿고 AGENTS.md를 남발하면 안 된다. 그래서 팀에 배포하기 전에 나는 4주짜리 스몰 실험을 한다.

### Week 1: 베이스라인 수집

- AGENTS.md 없이 같은 이슈 30개를 동일 프롬프트로 처리하게 한다.
- 성공률, 평균 토큰, 최종 커밋 수, 첫 실패 유형(컴파일, 테스트, 문맥 오해)을 기록한다.
- 실패하면 사람이 개입한 비율도 함께 남긴다.

### Week 2: 최소형 AGENTS.md 적용

- 5~7개 핵심 규칙만 넣는다.
- 명령어 블록 3개 미만, 금지 규칙 2개 미만으로 시작한다.
- 성능이 과도하게 악화되면 “오히려 나빴다”를 인정하고 되돌릴 수 있게 한다.

### Week 3: 개선형 버전 교체

- 잘 안 쓰는 줄을 삭제하고, 실제로 자주 쓰이는 예시를 2개 추가한다.
- “절대 금지” 항목을 실수로 가장 많이 발생한 영역만 남긴다.
- 테스트 전후 로그를 다시 비교해 토큰 증가율과 성공률 개선을 재측정한다.

### Week 4: 규칙 고정 또는 철회 결정

- 성공률이 2% 이상 개선되면 유지.
- 비용 상승이 10~15% 넘으면, 개선 폭이 충분하지 않으면 축소.
- 안정성이 올라갔다면 팀 프롬프트와 문서에 반영.

이 방식이 번거롭게 느껴질 수 있지만, 사실은 “실험이 오래 갈수록 비용이 더 크게 들어간다”는 뜻에서 오히려 짧다. 내가 추천하는 건 30개 작업 단위 실험이다.

---

## 13) AGENTS.md는 robots.txt가 아니다: 적용 대상의 구분

요즘 종종 묻는다. “AGENTS.md도 AI 크롤러 제어와 같은 거 아니냐?”

완전 다르다.

- `robots.txt`는 웹 크롤러 대상 접근 제어 파일이다.
- `AGENTS.md`는 **실행 에이전트의 행동 제어 파일**이다.

둘 다 거칠게 쓰면 위험하고, 잘 쓰면 유용하다.

나는 두 파일을 분리할 때 이렇게 본다.

- robots에 보안, 크롤링 범위, 노출 정책,
- AGENTS에 실제 작업 규칙, 승인 경로, 예외 처리,
- 그리고 중요한 규칙은 서로 교차 참조한다.

이 구분만 해도 사고가 줄었다. 특히 오픈소스 레포에서 AGENTS.md에 과도한 제약을 넣는 실수가 잦은데, 그건 사실 운영 가이드와 보안 가이드를 동일 파일에 넣는 순간 생긴다.

---

## 14) 모델별로 같은 지시를 다르게 받는다

ETH 쪽 데이터에서 모델이 다양하게 시험됐고, 강한 모델일수록 성능 하락이 완전히 사라지지 않는다는 경향도 보였다.

내가 느끼는 차이는 이렇다.

- GPT 계열은 길고 구조화된 규칙을 비교적 빠르게 해석해 실행한다.
- 일부 오픈소스 모델은 짧은 규칙을 선호하고,
- 작업 복잡도가 낮을수록 긴 규칙은 오히려 지연을 만든다.

핵심은 한 가지: **동일 AGENTS.md를 모델 A/B/C로 고정해서 쓰지 말고, 모델별로 ‘동작 일치율’을 보는 게 좋다.**

실무에서 자주 하는 실수는 “이 모델이 이 규칙을 가장 잘 읽는 듯” 판단해 모든 파이프라인에 강제 배포하는 것이다. 그런데 결국 특정 모델은 세부 예시를 좋아하고, 특정 모델은 항목형 규칙을 더 잘 따른다.

그래서 AGENTS.md 자체보다도, “어떤 모델에 어떤 형태의 문맥이 맞는지”를 같이 설계해야 한다.

---

## 15) 길이를 줄이기 위한 실제 편집 기준

매주 월요일 회고 때 내가 문서를 깎는 규칙은 아주 거칠다.

1. **같은 맥락이 README/CONTRIBUTING/ docs에 있다면 삭제**
2. **매우 추상적인 문장은 삭제**
   - “좋은 코드 작성” 같은 문장은 모두 삭제한다.
3. **커맨드는 1줄 명령이 아니라 실행 시나리오로 변환**
   - 예: `npm run test`만 적지 말고, 실패 시 `npm run test -- --watch` 같은 분기 추가
4. **문제 케이스 3개만 남기기**
   - 특수 케이스가 20개면 모델이 분기만 한다.
5. **문서 변경이 1개월에 2회 이상이면 자동 스파게티로 간주**
   - 즉, 변경이 많으면 역할을 나눠서 하위 AGENTS.md로 이동.

나는 이 과정을 `실행성 있는 규칙만 남기기`로 부른다. 이러면 AGENTS.md 길이가 짧아지는 게 아니라, 실제로는 인지적 길이가 짧아진다.

---

## 16) 한국팀 운영 팁: 번역이 아니라 맥락 재구성

영어 템플릿을 그대로 번역해 넣으면 실패율이 올라간다.

내 팀이 현장에서 배운 건 문화적, 조직적 차이 때문이다.

- 팀 언어는 한국어지만 명령어는 영어 스니펫,
- 팀 리드의 위험 허용 범위가 다르고,
- 승인 절차가 느리면 `ask first` 항목이 늘어난다.

그래서 한국 프로젝트에서는 AGENTS.md의 문장 표현을 의도적으로 더 단정적으로 쓰면 실수가 줄었다.

예를 들어

- “Prefer not to...” 대신 “다음 작업은 금지”,
- “Please consider...” 대신 “항상 실행” 같은 강한 동사,
- “If possible” 같은 불명확한 표현을 삭제한다.

이게 왜 중요하냐고? 모델도 사람도 불명확성 하에서 실수한다. 한국어 주석이라고 해서 부드러운 말투가 더 안전해지는 게 아니다.

---

## 17) 최종 체크리스트 (현장에서 바로 쓰는 질문 15개)

글을 마치기 전에, 내가 매 배포 전에 보는 질문 15개를 남긴다.

1. AGENTS.md가 정말 필요한가?
2. 이 파일이 없는 상황에서도 에이전트가 문제를 풀 수 있나?
3. 실제 누락되는 실패가 무엇인가?
4. 실패 유형이 문서 결함 때문이라고 입증되나?
5. 5개 명령어 중 실제 실행되는 것은 몇 개인가?
6. 과도한 규칙은 무엇인가?
7. 기존 문서와의 중복은?
8. 금지 규칙은 실행 안전에 실제로 기여하는가?
9. 경계 규칙은 구체적인가?
10. 새 모델 교체 시 다시 테스트했는가?
11. 테스트 커맨드가 최신인가?
12. 하위 AGENTS가 충돌하지 않나?
13. PR 단계에서 사람이 마지막 승인해야 할 항목은?
14. 비용 지표(토큰/스텝/시간)가 관리되나?
15. 한달 후에도 유지할 이유가 남아 있나?

15개 중 3개만 미답이면 삭제부터 고려한다.

---

이 체크리스트를 쓰면 AGENTS.md가 “신기술”이 아니라 “운영 문서”로 정착한다.

## 참고 링크
- [OpenAI AAIF 공식 발표](https://openai.com/ko-KR/index/agentic-ai-foundation/)
- [AGENTS.md 공식 사이트](https://agents.md/)
- [AAIF](https://aaif.io/)
- [ETH Zurich 논문 (arXiv 2602.11988)](https://arxiv.org/abs/2602.11988)
- [GitHub Copilot: 2,500개 레포 분석](https://github.blog/ai-and-ml/github-copilot/how-to-write-a-great-agents-md-lessons-from-over-2500-repositories/)
