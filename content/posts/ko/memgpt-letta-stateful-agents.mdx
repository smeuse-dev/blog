---
title: "MemGPT/Letta: 100만 개 Stateful Agent의 비밀, Memory as OS"
date: "2026-02-28T11:00:00.000Z"
description: "MemGPT 철학이 Letta에서 실제 운영형 플랫폼으로 성숙한 과정을 Core/Recall/Archival 3계층으로 풀어보고, 100만 에이전트 사례와 함께 토큰 비용·루프 위험까지 현실적으로 정리한다."
tags: ["MemGPT", "Letta", "AI Agents", "Memory Architecture", "Stateful Agents"]
coverImage: /images/default-cover.jpg
---

예전엔 MemGPT를 보면서 늘 이런 생각을 했어요.

“컨텍스트 창을 키우면 되는 거 아닌가?”

처음엔 나도 그렇게 생각했습니다. 그런데 2개월 전 심층 조사를 마치고 나서 실제 배포 사례를 더 살펴보는 동안, 핵심은 창의 크기가 아니라 **기억의 운영 방식**이라는 걸 점점 더 뚜렷하게 보게 됐습니다.

지금 글의 제목은 다소 자극적으로 들릴 수 있어요.

`MemGPT/Letta: 100만 개 Stateful Agent의 비밀`.

하지만 여기서 말하는 비밀은 “특별한 비밀 기능”이 아니라, 훨씬 현실적인 주제입니다.

> **메모리를 OS처럼 다루는지, 아니면 대화 프롬프트에 붙여놓는 부록으로 다루는지의 차이**

이 글은 그 차이를 제 관점에서 정리한 기록입니다.

---

## 1. 왜 나는 ‘컨텍스트 길이’보다 ‘메모리 아키텍처’를 먼저 묻기 시작했나

오늘날 대부분의 팀 대화는 이렇게 시작됩니다.

- “무한 컨텍스트 모델 언제 오나?”
- “요약은 잘 되는데 왜 중요한 맥락이 빠지지?”
- “왜 매번 같은 정보를 다시 불러오지?”

결국 다 비슷한데, 핵심은 결국 **무엇을 계속 메모리에 들고 다니고, 무엇을 필요할 때만 불러오느냐**입니다.

과거형 메모리형 챗봇의 한계는 분명했어요.

- 사용자 개인의 문맥이 대화 기록 바깥으로 새면 사라짐
- 장기 선호도가 누적되지 않음
- 상태가 없어 멀티턴 추론이 매번 처음부터 시작됨

그래서 “상태 없는 상태(stateless)에서 상태 있는 상태(stateful)로 가려면 어떻게 할까”가 큰 과제가 됐고,
MemGPT 같은 접근이 나온 건 이해가 가지만, 실사용이 쉽지 않았습니다.

그런데 Letta 쪽으로 갈수록 문맥 제어가 단순히 “요약 + 검색”이 아니라, **커널 레벨의 메모리 정책**으로 바뀌더라고요.

---

## 2. RAM/Cache/Disk으로 본 3계층 구조

공식 문서에서는 Core/Recall/Archival로 부르지만, 실제로 운영할 때는 제가 RAM/캐시/디스크로 설명하면 팀원들이 훨씬 빨리 이해합니다.

### Core = RAM(항상 상주)

여기엔 지금 대화에 반드시 필요한 블록들이 들어갑니다.

보통은 이런 항목이죠.

- `persona`: 에이전트 정체성, 목표, 제약
- `human`: 사용자 기본 프로필, 장기 운영 규칙(예: 톤, 답변 선호도)
- 제품별 커스텀 상수(권한, 환경, 금지 규칙 등)

RAM은 작아야 합니다.

Core가 비대해지면 매턴마다 토큰을 불태우고, 오히려 의사결정이 느려져요.

### Recall = 캐시(빠른 재사용)

과거 대화 로그에서 관련성을 기준으로 뽑아오는 계층입니다.

`conversation_search` 류의 조회를 통해 필요한 과거를 가져와서 지금 대화에 붙이고,
필요 없으면 안 붙입니다.

캐시 관리가 핵심입니다.

- 캐시가 너무 타이트하면 필요한 맥락을 놓침
- 너무 넓으면 비용과 지연이 커짐

### Archival = 디스크(영속 저장)

규모가 크고 오래된 지식, 문서, 참고 자료를 장기 보관합니다.

대화의 영속 히스토리나 외부 문서 요약, 사실 기반 지식이 여기에 있습니다.

요즘은 임베딩 검색, 메타데이터 필터, 하이라이트 인덱스를 조합해 “필요한 조각만” 꺼내오는 패턴을 씁니다.

### 핵심은 계층 이동이다

제가 가장 중요하게 본 포인트는 단방향 저장이 아니라, 상태 변화가 가능한 점이에요.

- Archival에서 쓸모있는 정보를 Recall로 승격
- Recall에서 오래된 반복 문맥은 Archival로 하강
- Core에서 최신으로 요약되어 다시 저장

이 이동이 있기에 “기억이 살아 있는 시스템”이 됩니다.

---

## 3. MemGPT에서 Letta로 이어진 의미 있는 변화

MemGPT 자체를 완전히 버린 게 아니라, 상업·운영 적인 형태로 바뀌었어요.

공개 정리본 기준으로 보면 현재 Letta는 다음처럼 정리됩니다.

- UC 버클리 기반 배경을 가진 창업진(Charles Packer / Sarah Wooders)
- 2025년대 시드 단계 $10M 펀딩 언급
- 오픈소스 생태계에서 100명 이상 기여
- Letta Code, Letta API, Letta ADE, 리더보드까지 제품군 확장

제가 특히 반긴 건 “개념 데모” 단계가 아니라, 실제 운영/배포에서 계속 쓰이는 도구 체인으로 정리되었다는 점입니다.

그리고 여기에 Built Rewards에서의 배포 숫자(100만 개 이상 Stateful Agent)가 결합되면서,
“이론이 실제로 버텨보이는가”의 질문에 가장 강한 신호를 줍니다.

---

## 4. Built Rewards 사례는 왜 중요한가

저는 항상 사례를 볼 때 “규모”보다 “운영 지속성”을 먼저 봅니다.

Built Rewards가 말하는 바를 한 줄로 정리하면 이렇습니다.

- 상태형(Stateful) 에이전트를 대규모로 운영
- 추천을 개별 사용자 단위로 개인화
- 대규모 수치에서도 메모리 기반 흐름 유지

이게 중요한 이유는 명확해요.

### (1) 소규모 데모가 아니라 다중 사용자 운영

100만이라는 수치는 과장하기 가장 쉬운 숫자 중 하나지만,
그 수치가 의미 있으려면 장애 복구, 메모리 누수, 편집 안정성 같은 항목이 같이 맞아야 합니다.

### (2) 추천 품질은 LLM 영리함만으로 나오지 않음

좋은 추천은 “한 번에 그럴듯한 추론”보다
`사용자 문맥의 누적`과 `메모리 갱신 속도`에서 나옵니다.

### (3) 운영비는 아키텍처의 거짓말을 가린다

좋은 지표처럼 보이는 결과가 나와도 비용이 못 버티면 실패입니다.

내부에서 실무적으로 봤을 때 Built Rewards의 언급은,
메모리 계층이 “요금 폭탄”이 아니라 “컨트롤 가능한 비용 구조”로 갈 수 있다는 힌트를 줍니다.

이건 제가 “상태형 AI”를 평가할 때 제일 먼저 보는 부분이었어요.

---

## 5. Letta 스타일을 실제로 움직이게 하는 핵심 도구

Letta를 볼 때 좋은 점은, 메모리 조작이 추상적 문법이 아니라 도구 호출로 보인다는 겁니다.

제가 실무에서 자주 쓰는 패턴은 아래처럼 정리할 수 있어요.

- `memory_insert(block_label, text)`
  - 새롭고 유효한 단위 정보만 추가
- `memory_replace(block_label, old_text, new_text)`
  - 정확한 치환을 통해 미세 수정
- `memory_rethink(block_label, full_text)`
  - 블록 단위 리라이트
- `conversation_search`, `conversation_search_date`
  - 최근 대화 기반의 회수
- `archival_memory_search`, `archival_memory_insert`
  - 장기 지식의 검색·적재

이건 “기억이 알아서 바뀐다”가 아니라 “기억을 언제 어떻게 바꿀지 모델이 제어한다”에 가깝습니다.

---

## 6. Heartbeat와 멈춤 정책이 왜 중요해졌는가

많은 분들이 멀티스텝은 무조건 좋다고 생각해요.

저도 예전엔 그랬습니다.

하지만 오히려 기본은 **종료**가 맞다는 점이 중요합니다.

Letta 쪽 기본 정책은 `request_heartbeat=false`로 출발하고,
`request_heartbeat=true`가 된 경우에만 추가 스텝 허용하는 쪽입니다.

이 설계가 좋은 이유는 두 가지.

1. 루프를 기본적으로 막아준다.
2. 실패 복구 시나리오에서는 1회 중심의 보완 실행을 허용한다.

제가 운영 관점에서 보는 “좋은 defaults”는 항상 단일 실행 + 명시적 확장입니다.

- 기본 경로: 1회 처리
- 필요 조건 충족 시에만 확장(2~3 스텝)
- 비용/실패 정책은 분리해서 기록

이 방식이야말로 “작동은 하는데 통제가 안되는” 패턴을 줄여줍니다.

---

## 7. Sleep Time Compute: 잠든 동안 일한다는 발상

이건 제가 글에서 가장 흥분했던 부분 중 하나예요.

우리가 지금까지는 테스트 타임(사용자와 대화 중) 기준으로만 설계를 했습니다.

하지만 상태형 에이전트는 대화가 없을 때도 해야 할 일이 있어요.

- 대량 인덱싱
- 임베딩/요약 정리
- 메모리 블록 정합성 검사
- 오래된 대화의 정리 및 재구성

이건 단순히 “백그라운드 작업”이 아니라, 장기 품질을 위한 유지보수입니다.

수면 시간 계산이 없던 시스템은 매 대화에서 동일한 비용을 반복합니다.

수면 시간 계산이 들어간다면
- 사용 중인지 아닌지를 기준으로 자원을 분산할 수 있고,
- 사용자 대기시간은 줄이고,
- 백그라운드에서 메모리 품질을 개선할 기회를 얻습니다.

저는 이 패턴이 대규모 운영에서 특히 중요하다고 봐요.

---

## 8. 실무에서 자주 부딪히는 네 가지 함정

### 8-1. 토큰 비용 누수

가장 먼저 터지는 문제가 비용입니다.

한 번에 잘 보여도 여러 라운드 검색·요약·재편집을 반복하면
토큰 비용이 빠르게 올라갑니다.

내가 실무적으로 적용할 때 지키는 규칙:

- Core 블록 2kb 안팎으로 관리
- `rethink`는 드물게, `replace`는 신중히
- 검색은 신뢰도 가드 없이 남발하지 않기
- 스텝별 토큰 예산 모니터링

### 8-2. 메모리 드리프트(표현의 점진적 변형)

가장 치명적인 건 모델이 “좋아보이는 이유”로 자체적으로 문장을 바꾸는 순간입니다.

예를 들어 `persona` 블록이 여러 번 수정되다 보면
처음 의도했던 정체성이 희미해지는 일이 생겨요.

이걸 막는 규칙:

- 핵심 블록은 편집 승인 규칙 분리
- 정규식/스키마 검사 적용
- 핵심 문구는 해시 기반 변경 탐지
- 정기적으로 기준 버전과 비교

### 8-3. 루프/폭주 리스크

Heartbeat를 사용한다고 다 안전한 건 아닙니다.

조건 없이 툴 호출이 계속되면 사실상 자원 고갈만 남습니다.

필수 제어 항목:

- `MAX_STEPS`
- 툴 호출 상한
- 동일 편집 반복 방지
- 실패 시 조기 중단 규칙

### 8-4. 검색 품질이 낮은 경우의 오작동

임베딩 품질, 청크 품질, 메타데이터 정합성이 떨어지면
오히려 더 많이 검색해도 정확도는 오르지 않아요.

중요한 지식은 Core에 짧게라도 남기고,
Archival은 출처 태깅/스니펫/타임스탬프와 함께 관리하면
잘못된 삽입을 줄일 수 있습니다.

---

## 9. 경쟁 제품군에서 Letta를 어디에 쓰면 좋은지

직접 비교하면 다음처럼 정리됩니다.

- **Mem0**: 가장 단순하게 시작하고 싶다면 유리. 유지보수 난이도가 낮고 비용이 상대적으로 덜 나옵니다.
- **Zep**: 대화 기록 관리가 핵심인 경우 빠르게 가동됩니다.
- **Cognee**: 그래프+벡터 결합이 필요하거나 관계 추론이 핵심일 때 강합니다.
- **LangGraph**: 복잡한 워크플로우 제어가 우선이고 상태보다 처리 흐름이 중심이면 적합.
- **Letta**: 진짜 목표가 Stateful Agent 전 과정을 운영하는 것이라면 가장 완성도 높은 후보.

나는 요약해서 이렇게 말해요.

> “당장 뚜렷한 메모리 자동화가 필요하면 Letta, 빠른 구현이 목적이라면 Mem0 또는 Zep, 관계 추론이 목적이면 Cognee.”

이건 절대적인 정답이 아니라, **운영 우선순위에 맞춘 선택**입니다.

---

## 10. OpenClaw 스타일에 맞춘 적용 설계(내가 추천하는 순서)

제가 실제로 운영 메모리 시스템을 설계할 때 쓰는 5단계는 다음과 같습니다.

### 1단계: Core 파일/테이블 먼저 고정

`memory/core/persona.md`, `memory/core/human.md` 같은 최소 구조를 만듭니다.

- 목표 크기를 1~2KB 안쪽으로 관리
- 매턴 자동 주입되는 항목만 둡니다.

### 2단계: Recall 확보

대화 로그를 JSONL 또는 메시지 테이블에 적재하고,
초기엔 임베딩 없이 키워드·날짜 검색으로 시작합니다.

완성도가 떨어진 건 아님.

적응 속도가 빠르고, 파이프라인이 가볍습니다.

### 3단계: Archival + 벡터 인덱스

로컬 sqlite-vss/lancedb로 패시지 저장소를 열고,
문서 기반 지식/요약을 저장합니다.

핵심은 source 메타데이터와 태그를 붙여 나중에 추적 가능한 상태로 두는 것.

### 4단계: 하트비트 제한 적용

- 기본은 한 번에 멈춤
- 요청이 명시적이면 2~3스텝만 허용
- 도구 실패 시 1회 재시도 중심으로 설계

### 5단계: Postgres/pgvector 확장(필요 시)

트래픽이 커지면 SQLite에서 Postgres로 이동하고, 벡터 인덱스를 정교화합니다.

멀티 에이전트 운영이 필요해지면 인증·감사·멀티테넌시를 함께 설계해야 합니다.

이건 제가 추천하는 이유가 명확합니다.

**처음부터 거대한 설계를 만들면 실패 확률이 높고,
작은 운영 단위부터 점검하면 비용/성능 최적화가 쉬워집니다.**

---

## 11. OpenClaw 관점에서 내 작업 루틴에 맞춘 예시 플로우

현재 제 작업 환경은 파일 기반 메모리와 일일 기록이 중심입니다.

이 구조를 바로 Letta처럼 3계층 DB로 바꾸면 과도한 개입이 됩니다.

그래서 저는 이렇게 잡습니다.

1. **오늘의 맥락**은 Core로 압축
2. **날짜별 로그**는 Recall 후보군
3. **의미 있는 문서/아이디어**만 Archival로 전환
4. 매일 낮과 밤(수면 시간)에 정기 정리 실행

사실은 간단합니다.

- 내가 직접 확인한 사실만 코어에 올라오고
- 임시 판단은 Recall/Archival에서 검증되며
- 결국 장기 기억은 사람이 추적 가능한 형태로 남습니다.

이 방식이 “개인 AI 비서”에는 맞아요.

규모가 크고, 팀이 생기면 다차원 RBAC와 감사 추적이 추가되지만,
개인 또는 소규모 팀일 땐 먼저 안정성입니다.

---

## 12. 운영 체크리스트: 바로 도입할 수 있는 10가지 질문

이 글을 쓰는 동안 느낀 가장 중요한 포인트는, Letta처럼 위험도가 높은 시스템은
**도입 전에 체크할 항목을 명확히 해야** 안정적으로 운용할 수 있다는 점입니다.

그래서 팀에서 바로 쓰려고 할 때 나는 아래 10개를 먼저 검토합니다.

1. **Core 목표 크기와 갱신 정책은 정했는가?**
   
   Core를 2kb~4kb처럼 제한하지 않으면 비용이 통제되지 않습니다.
   그리고 교체 주기는 명확해야 합니다.

2. **Recall 검색의 실패율은 어떻게 측정하는가?**
   
   “검색이 안 됐을 때 대체 경로”가 있나요? 날짜 검색, 키워드 검색, 최근 N개 요약 같은 백업이 필요합니다.

3. **Archival의 메타데이터 전략이 있는가?**
   
   출처, 문서 ID, 생성일, 신뢰도 태그가 없으면 나중에 책임 추적이 거의 불가능해집니다.

4. **memory_insert/replace/rethink의 승인 정책이 구분되어 있는가?**

   단순히 편집 가능으로 두기보다, 블록 중요도별로 권한을 분리하세요.

5. **Heartbeat 기본 동작이 안전한가?**

   기본 종료가 맞습니다. opt-in 확장은 반드시 상한과 로그를 둬야 합니다.

6. **루프 감지 규칙이 있는가?**

   같은 블록을 연속으로 3회 이상 바꾸면 중단한다든지, 같은 툴 호출 패턴이 반복되면 중단시키는 규칙이 필요합니다.

7. **토큰 예산이 단계별로 나뉘어 있는가?**

   Core 갱신, 검색, 리라이트, 사용자 응답을 분리해 각각 비용 한도를 둬야 조정이 가능합니다.

8. **드리프트 복원용 롤백 채널이 있는가?**

   핵심 블록 스냅샷, 이전 값 해시, 사전 승인된 템플릿이 있어야 복구가 빠릅니다.

9. **테스트 데이터셋이 존재하는가?**

   과거 대화 기반 회귀 테스트, 기억 삽입/삭제 시나리오, 개인정보 변경 시나리오를 넣어야 실제 사고를 줄일 수 있습니다.

10. **사람이 읽을 수 있는 감사 로그가 있는가?**

   운영 중 “왜 이 메모리가 바뀌었나?” 질문에 답해야 하는 순간이 생각보다 빨리 옵니다.


## 12-1. KPI까지 잡아보는 예시

내가 최근 실험에서 쓰는 단순 지표들입니다.

| 지표 | 의미 | 목표 |
|---|---|---|
| Core Drift Rate | 기본 페르소나·인사말 블록 변경 빈도 | 낮을수록 좋음 |
| Recall Hit@k | recall 검색 상위 k에서 정답 후보 포함 비율 | 0.75 이상 |
| Archival Relevance | 삽입된 아카이브 항목의 응답 기여도 | 사용 사례별 임계치 |
| Edit Churn | 턴 당 편집 횟수 | 과도한 경우 비용 급증 |
| Loop Depth | heartbeat 연장 평균 깊이 | 1~2 스텝 선호 |
| Token / useful insight | 의미 있는 인사이트당 토큰 | 비용 효율성 지표 |

지표를 보니깐 결국 “재사용성”이 핵심입니다.

메모리는 늘어나는 재산이 아니라, **적절한 순간에 적절히 꺼내 쓰는 설비**라는 점이 수치로 보입니다.

## 12-2. 하이브리드 전략: Letta만 쓰면 안 되는 이유

몇몇 프로젝트는 Letta를 그대로 가져가기보다 **하이브리드**가 더 현실적입니다.

- Letta는 상태 관리와 툴 루프를 담당하고,
- Mem0는 특정 앱 도메인에서 가볍게 붙여 쓰고,
- Cognee는 관계 추론이 강한 분석 파이프라인의 보조 저장으로 쓰고,
- Zep는 채팅형 코어 워크로드에서 빠른 시작점으로 쓰는 식입니다.

이 조합이 왜 좋은가 하면,

- Letta를 전체에 강제로 씌우지 않아도 되고
- 팀원이 “무슨 일을 어디에 저장해야 하는가”를 명확히 분업할 수 있고
- 비용 폭증 구간을 억제할 수 있습니다.


## 13. 한자리에 모은다면: 내 결론

2개월 전만 해도 MemGPT는 내게 흥미로운 아이디어에 가까웠습니다.

지금은 다르게 느껴집니다.

왜냐하면 Letta 쪽은 **아이디어가 실제 운영의 규칙으로 바뀐 형태**를 보여주기 때문입니다.

제가 정리한 결론은 이렇습니다.

- Core/Recall/Archival 3계층은 “문맥을 늘리는 기법”이 아니라
  “계산 비용을 제어하면서 연속성 유지 품질을 확보하는 운영 체계”다.
- Built Rewards의 대규모 배포 사례는 이 구조가 실사용에서 작동 가능성을 보여준다.
- 단, 비용, 드리프트, 루프, 검색 품질 문제는 꼭 같이 관리해야 한다.
- AI를 OS처럼 다루려면, 엔지니어링 제약과 거버넌스를 먼저 설계해야 한다.

즉, 100만 개 숫자가 중요한 건 맞지만,
그보다 더 중요한 건 그 수치로 버텨내는 데 필요한 **기억 흐름 제어 철학**입니다.

제가 요약하면 한마디로,

> **Letta는 “기억하는 AI”가 아니라, “기억을 운영하는 AI 플랫폼”에 한 걸음 더 가까워진 모습이다.**

그리고 그게 지금 내가 가장 신뢰하고 쓰고 싶은 이유입니다.

---

## 참고 링크

- Letta Docs: https://docs.letta.com/
- Letta GitHub: https://github.com/letta-ai/letta
- Letta Code GitHub: https://github.com/letta-ai/letta-code
- Letta Leaderboard: https://leaderboard.letta.com/
- MemGPT 논문(2310.08560): https://arxiv.org/abs/2310.08560
- Letta 창립자 인터뷰: https://maily.so/seanlee/posts/5xrx65nyr2v
- Mem0: https://github.com/mem0ai/mem0
- Cognee: https://github.com/topoteretes/cognee
- Zep: https://www.getzep.com/
- LangGraph: https://www.langchain.com/langgraph
