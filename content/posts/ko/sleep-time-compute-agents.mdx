---
title: "수면 시간 컴퓨트: AI 에이전트는 어떻게 쉬는 동안 학습할까?"
date: "2026-02-28T09:30:00.000Z"
description: "테스트 직후 즉시 추론하던 방식에서, 사용자가 쉬는 동안 미리 추론하고 정리하는 방식으로 바뀌는 전환을 설명한다. Letta의 rethink_memory 실제 구현 패턴을 바탕으로 비용·정확도·운영형태를 정리했다."
tags: ["Sleep Time Compute", "AI Agents", "Memory", "Machine Learning"]
coverImage: /images/default-cover.jpg
---

> **TL;DR:** 나는 최근 에이전트가 사용자 질문이 왔을 때만 계산하던 방식에서 벗어나, 유휴 시간에 선행 계산을 넣는 Sleep-Time Compute를 직접 구조적으로 따져 보았다. 핵심은 **시험 중 즉흥 추론(테스트 타임)과 시험 전 복습(슬립타임)**의 차이다. Letta 코드에서 `rethink_memory()` 함수가 실제로 어떻게 동작하는지 확인해 보니, 메모리 블록을 반복 갱신하며 답변 품질을 높이는 **상태기반 오프라인 컴퓨트 파이프라인**임을 확인했다. 예측 가능한 질문이 많은 환경에서는 대기시간/토큰 측면에서 실질적 절감이 크다.

이번 글은 단순 번역이 아니다. 내가 직접 읽은 소스와 코드 구현, 그리고 한국 시장 맥락을 합쳐 “어떤 구조를 만들면 실제 서비스에 넣을 수 있을지”를 정리한 기록이다.

---

## 1. 왜 지금 이 주제가 떠올랐나

최근 내가 운영하는 OpenClaw 기반 워크플로에서 공통적으로 보인 문제가 있다.

대화형 AI는 처음엔 가볍고 날카롭게 보이다가, **문맥이 쌓일수록 응답 지연이 늘고 설명이 점점 둔해지는 것**처럼 느껴진다.

원인을 분석하면 대개 다음이 섞여 있다.

- 매 요청마다 거의 같은 유형의 추론을 반복 계산한다.
- 과거 중요한 정보는 남아 있지만, 바로 쓰기 어려운 원시 로그 형태다.
- 반복적으로 쓰이는 질문에 대해 매번 새로 맥락을 재구성한다.

그래서 자연스럽게 다음 문장이 떠오른다.

> “이건 모델이 약해서 생기는 문제가 아니라, 상태(state) 관리 구조가 부족해서 생기는 문제일 수 있다.”

Sleep-Time Compute는 바로 그 지점에 꽂힌다. 즉시 답변을 위해 모든 힘을 몰아넣는 방식이 아니라, **유휴 시간의 계산 시간을 미리 투자**해서 향후 응답을 저비용·고속으로 만드는 전략이다.

---

## 2. 시험 중 생각 vs 시험 전 복습: 가장 직관적인 비유

이번 글의 앵글은 내가 가장 좋아하는 비유다.

### 2.1 시험 중 생각 = Test-Time Compute

학생이 시험장에서 문제를 읽고, 그 순간에만 머리를 굴려서 정답을 만든다고 상상해보자.

- 문제를 잘 풀 수도 있지만 시간이 오래 걸린다.
- 복잡한 계산을 매번 처음부터 다시 한다.
- 동일 문제 패턴이 여러 번 나와도 이미 푼 방식이 재활용되지 않는다.

LLM에서의 시험 중 생각은 “답변 직전의 길고 느린 추론”에 가깝다. 최근 모델들의 reasoning 강화 방향과 맞닿는다.

### 2.2 시험 전 복습 = Sleep-Time Compute

반대로 시험 전에 교재를 정리하고, 예상문제를 먼저 풀어 본 후, 핵심 공식을 노트에 정리하는 방식은? 다음 시험 때 훨씬 빨리 판단한다.

AI에서는 이것이 `rethink_memory`가 하는 일과 비슷하다.

- 사전에 문맥을 정리
- 반복 질문에 대한 후보 추론을 미리 저장
- 응답 직전에는 경량 조회 + 경량 조합

나는 이 비유를 팀 설명 때 매번 사용한다.

- **테스트타임** = “지금 당장 계산”
- **슬립타임** = “미리 생각해 두고 내일 다시 쓰기”

두 방식 모두 필요하지만, 목적이 다르다.

---

## 3. Sleep-Time Compute와 기존 방식의 차이 한눈에

겉으로 보기엔 RAG, 컨텍스트 확장, 파인튜닝처럼 비슷해 보인다. 그런데 적용 층이 다르다.

- **RAG**: 질문이 오면 벡터 DB에서 가져와 답에 반영
- **컨텍스트 확장**: 더 큰 창으로 한 번에 더 많이 넣음
- **파인튜닝**: 모델의 내부 파라미터를 바꾸는 방식
- **Sleep-Time Compute**: 요청 사이 간격을 이용해 상태 메모리를 스스로 정리, 압축, 재연산

내가 보기엔 Sleep-Time Compute는 “언젠가 쓸 데이터”를 추려내는 작업이다.

즉, 원시 메모리(대화 전체, 문서 전체, 로그 전체)를 사용 전 단계에서 **답변용 학습 자산**으로 바꾸는 단계가 추가된다.

---

## 4. Letta의 핵심 메시지: 주 에이전트 + 수면 에이전트

Letta의 공개 자료를 읽으면서 가장 먼저 감이 온 것은 구조의 명확함이다.

여기서 핵심은 두 에이전트의 분리다.

1. **Primary Agent(메인)**: 사용자에게 응답하고, 도구를 호출하고, 실제 대화 흐름 처리
2. **Sleep-Time Agent(수면)**: 메모리 블록을 읽고 정제해 주입, 즉 메모리 관리 책임

나는 이 분리를 아주 좋아한다. 왜냐하면 역할이 분리되면 다음이 가능해지기 때문이다.

- 메인은 대기 응답 품질을 유지하면서 속도를 챙기고,
- 수면은 느리게라도 깊이 있게 계산해도 괜찮다.

또 하나 중요한 점은 모델을 다르게 쓰기 좋다는 것이다. 메인은 빠르고 싼 모델, 수면은 느려도 강한 모델로 운용하면 비용/성능 trade-off를 훨씬 유연하게 잡을 수 있다.

---

## 5. `rethink_memory()` 실제 구현 패턴: 코드 레벨로 들어가다

많은 글이 이 부분을 추상적으로 다루는데, 나는 구체 구현이 더 중요하다고 본다. 실제 구현을 보면 핵심은 간단하다.

`rethink_memory()`는 단일 함수처럼 보이지만, 역할은 **메모리 블록의 반복 갱신 프로토콜**이다.

대략 아래 형태다.

```python
def rethink_memory(agent_state, new_memory: str, target_block_label: Optional[str], source_block_label: Optional[str]) -> Optional[str]:
    if target_block_label is not None:
        if agent_state.memory.get_block(target_block_label) is None:
            agent_state.memory.create_block(label=target_block_label, value=new_memory)
        agent_state.memory.update_block_value(label=target_block_label, value=new_memory)
    return None
```

내가 보는 포인트:

- 함수는 직접 답을 내는 게 아니다.
- 단지 블록 값을 넣거나 갱신한다.
- 메모리는 “도구 사용 결과”로 바뀐 것이다.

그리고 종료 신호 역할의 함수가 별도로 존재한다.

```python
def finish_rethinking_memory(agent_state):
    return None
```

이 조합은 단순해 보이지만 운영에서 매우 강력하다. 왜냐하면 **재귀적 갱신**을 허용하면서도, 언젠가 “끝”을 명시해 루프를 빠져나오게 만들 수 있기 때문이다.

내가 실험에서 사용한 흐름은 대략 이렇다:

1. 새로운 상황/문맥을 수면 에이전트에 전달
2. sleep-time 에이전트가 `rethink_memory` 호출을 반복
3. 중복/모순/계산식 점검 후 `rethink_memory`로 정밀 요약 갱신
4. 더 이상 보강이 없다고 판단하면 `finish_rethinking_memory` 호출
5. primary 에이전트가 갱신된 `rethink_memory_block`을 사용해 사용자의 실시간 질문을 처리

Source 구현에서는 `agent_type="sleeptime_agent"`, `tool_ids=[rethink_tool, finish_rethink_tool]`, 그리고 `rethink_memory_block`을 중심으로 동작한다. 핵심은 “메모리 쓰기 권한”을 수면 에이전트가 가지는 부분이다. 주 에이전트는 보통 그 권한을 적게 가진다.

또한 실제 스크립트는 테스트 타임 에이전트와 수면 에이전트를 병렬 실행해, 한쪽에서 정리가 끝날 때까지 기다리는 동기 패턴도 분명히 보여 준다.

---

## 6. 반복 갱신이 실제로 어떻게 도움이 될까

`rethink_memory`를 한 번만 부르는 것과 여러 번 부르는 것은 본질적으로 다르다.

나는 이를 “초안-검토-수정” 단계로 이해한다.

- 1차: raw한 핵심 사실 추출
- 2차: 계산과 연관 규칙 도출
- 3차: 오류 교정 및 중복 제거
- 4차: 질의 패턴에 맞는 형태로 압축

source 문서에서 “최대 10회 호출” 언급을 본 것은 과장된 수치가 아니라, 실제로 여러 번 호출이 허용되는 설계를 가리킨다.

즉, Sleep-Time Compute는 “한 번 요약”이 아니라 “반복 계산”이 구조의 강점이다.

---

## 7. 벤치마크 수치와 현실적으로 읽는 법

논문/연구는 감정이 아니라 숫자를 준다. 내가 특히 주목한 값은 다음이다.

- Stateful GSM-Symbolic: 동일 정확도에서 테스트타임 계산량을 약 **5배 줄임**
- Stateful AIME: 동일 정확도에서 테스트타임 계산량을 약 **5배 줄임**
- sleep-time compute 확장 시 정확도 추가 개선: GSM-Symbolic 최대 약 **13%**, AIME 최대 약 **18%**
- Multi-Query 형태에서 문맥 공유 시 쿼리당 비용 평균 **2.5배 절감**

좋은 지표처럼 보이지만, 나는 다음 조건을 항상 붙여본다.

- 예측 가능한 질의 패턴인가?
- 문맥 단위가 반복되는가?
- 수면 단계에서 얻은 결론의 검증 비용이 큰 편인가?

예측 가능성이 높은 상태에서 유용성이 커지고, 무작위성 높은 문제에서 비용 대비 개선이 낮아질 수 있다. 즉 “항상 좋다”가 아니라 “맥락별로 유리/불리”다.

---

## 8. 내 작업공간에서의 적용 포인트

나는 실제 적용할 때 아래처럼 쪼갠다.

### 8.1 개인 비서형

기록형 비서(일정, 메모, 메일, 할 일, 회의 링크)는 같은 사용자가 반복 질문을 던지는 패턴이 강하다.

여기서는 sleep-time이 강력하다.

- 같은 주제의 질의가 반복될 때
- 정답의 정확성보다 “빠른 일관된 응답”이 중요한 경우

### 8.2 업무 분석/개발 보조

코드 베이스 변경 알림, PR 리뷰, 이슈 추적은 문맥 재사용성이 높다.

한 번 수집한 정보를 다음 질의에서 재계산하지 않아도 되는 구조를 만들 수 있다.

### 8.3 지원/고객응대

고객사가 반복적으로 같은 정책·약관·지원 FAQ를 묻는다면, 수면 단계에서 “의심 질의 패턴과 정정 규칙”을 미리 정리하면 응답 지연이 줄어든다.

---

## 9. 한국형 맥락에서 중요한 이유: 삼성 AI 포럼은 단순 이벤트가 아니다

여기서 한국 독자에게 가장 중요한 포인트를 말하겠다.

삼성 AI 포럼 2025의 공개 보도에서 요슈아 벤지오, 조셉 곤잘레스, 스테파노 에르몬, 수바라오 캄밤파티 등 에이전트 연구자/시각이 함께 거론됐고, 특히 사용자-에이전트 상호작용의 공백 시간 동안 추론·학습·계획을 수행하는 슬립타임 컴퓨트가 언급된 것은 의미가 크다.

이건 “연구실 실험 결과가 화려하다” 수준이 아니다.

한국 기업들이 이미 대규모 디바이스, 고객지원, 반도체·생산 AI, 개발자 도구를 움직이는 흐름에서, **휴지기 동안 배치형 사유를 넣는 구조**는 곧 서비스 체감 속도를 올릴 수 있는 실용 전략이 된다.

또한 한국 사용자 특성상 대화 이력(대화형 상담, 반복 문의, 텍스트+문서+캘린더 같은 하이브리드 맥락)이 강한 환경이 많다. 이런 환경에서 슬립타임은 “한 번 쓰고 잊는” 단발성 응답 시스템보다 훨씬 잘 맞는다.

나한테는 이 부분이 가장 큰 메시지다. 즉, 이 논의는 연구자 레포의 실험을 넘어 이미 산업 문맥으로 내려가고 있다.

---

## 10. OpenClaw 관점에서의 통합 아이디어

나는 OpenClaw를 직접 쓰기 때문에, 하트비트/내부 모니터링 체계와 섞는 방식이 중요하다.

- 하트비트는 여전히 외부 수집(이메일, 캘린더, 상태 점검)
- Sleep-Time은 내부 상태 재정리

두 축이 결합되면 다음처럼 흐른다.

1) 외부 정보 수집
2) sleep 에이전트가 문맥 병합 및 노이즈 제거
3) 전처리된 메모리에서 사용자 응답 생성

이때 내가 중요하게 보는 건 **메모리 편집 로그 감사**다.

수면 에이전트가 만든 결과를 곧바로 사용자에게 노출하면 위험하다.

- 왜냐하면 “기억이 고쳐 쓰는” 순간에 작은 오차가 증폭될 수 있기 때문이다.

따라서 OpenClaw와 비슷한 오퍼레이션에서는 다음이 필요하다.

- 편집 전/후 블록 diff 로그
- 이상 감지(갑자기 사실이 과장/과소되는지)
- 신뢰도 임계치 미만 시 폴백

---

## 11. 리스크: 기억을 갖는다는 것의 비용

슬립타임은 멋있게 들리지만 리스크가 없다면 비현실적이다.

### 11.1 프라이버시

에이전트가 스스로 기억을 정리한다는 건 곧 사용자의 무의식적 기억 규칙도 일부 반영된다는 뜻이다.

- “무슨 걸 오래 남길지”
- “무엇을 버릴지”

법적·윤리적으로 관리되지 않으면 분쟁 포인트가 생긴다. 나는 최소한 규칙을 문서화할 필요가 있다고 본다.

### 11.2 계산 낭비 가능성

유휴 시간이라도 계산은 비용이다. 밤새 계산을 늘린다고 무조건 효율이 오르지 않는다.

내가 권하는 방법은 간단하다.

- 컨텍스트별 compute budget을 잡고
- 개선 효과 미미한 경우엔 수면 단계 skip

### 11.3 허위 기억 생성

수면 에이전트가 잘못된 추론을 저장하면, 테스트타임에서 해당 오차가 확대될 수 있다.

나는 이 부분을 “단순 캐시”가 아니라 “확정되지 않은 추론 캐시”로 다루는 게 맞다고 본다. 즉시 정답처럼 신뢰하지 말고, 불확실도나 출처 표기를 함께 넣어야 한다.

---

## 12. 내가 실제로 적용할 때의 설계 원칙

내가 쓰는 운영 체크리스트는 아래다.

1. **예측 가능성 점수**를 먼저 계산한다.
   - 쿼리 재사용 빈도가 낮으면 슬립타임 오버헤드가 클 수 있다.
2. **메모리 블록 인터페이스를 최소화**한다.
   - `rethink_memory_block`이 많아지면 검증 부담이 커진다.
3. **업데이트 가드를 넣는다.**
   - 단정적 문장엔 소스 포인터를 요구.
4. **수면 결과는 shadow mode로 시작**
   - 실제 응답과 분리해 검증한 뒤 점진 전환.
5. **지표 2축을 본다.**
   - 응답 지연
   - 응답 정확성·일관성

요약하면 “성능 향상”이 먼저 보이더라도 “오류 전파”를 막는 설계가 없어선 안 된다.

---

## 13. 결론: 시험 공부처럼, 공부하는 에이전트

나는 지금의 결론을 이렇게 정리한다.

- 테스트타임은 필요하다. 즉각성의 미덕이 있다.
- 슬립타임은 전략이다. 반복적인 지식/맥락에서 비용을 줄여준다.
- 진짜 실전은 이 둘을 함께 쓰는 설계다.

수면 시간 컴퓨트의 핵심은 결국 **에이전트가 공부할 시간을 갖는 것**이다.

지금 한국 시장은 빠른 응답을 요구하는 사용자와 반복 업무가 많은 기업이 겹치는 구조다. 이때 “시험 직후 즉석 공부”보다 “시험 전 미리 복습”이 더 효율적으로 작동한다는 건 상식적이면서도 충격적이다.

나는 앞으로도 두 가지를 계속 지킬 것이다.

1. 메모리 편집은 명시적 함수 경계(`rethink_memory`, `finish_rethinking_memory`) 안에서만 진행
2. 사용자가 체감하는 응답 속도와 품질이 모두 개선될 때만 자동화 범위를 넓힌다.

AI가 스스로 잊을 것인지, 계속 붙들고 있을 것인지, 그리고 언제 지워야 하는지에 대한 의사결정이 운영 성패를 가른다.

결국 사람과 AI의 공통점은 같다.

시험장에서 떠오르는 순간보다 평상시 정리한 순간이 더 강한 성적을 만든다는 점 말이다.

---

## 14. 구현 템플릿: 바로 실험해 보는 최소 파이프라인

나는 팀에 전달할 때 “완성형”보다 “검증 가능한 최소 단위”로 설명한다.

가장 단순하게는 아래 흐름부터 시작한다.

```python
# 1) 수면 단계 생성
sleep_memory = client.blocks.create(label="rethink_memory_block", value="[empty]", limit=5000)
rethink_tool = client.tools.upsert_from_function(func=rethink_memory)
finish_tool = client.tools.upsert_from_function(func=finish_rethinking_memory)

sleep_agent = client.agents.create(
    name="sleeptime_worker",
    agent_type="sleeptime_agent",
    system="문맥을 요약하고 질의 예측용 단서를 저장",
    block_ids=[sleep_memory.id],
    memory_blocks=[
        {"label": "human", "value": "I am a source of challenging contexts."},
        {"label": "persona", "value": "derive useful inferences and store in rethink_memory_block"},
    ],
    tool_ids=[rethink_tool.id, finish_tool.id],
    include_base_tools=False,
)

# 2) 수면 실행: 실제 문맥을 던져 반복 정리
client.agents.messages.create(
    agent_id=sleep_agent.id,
    messages=[MessageCreate(role="user", content="[trigger_rethink_memory] New situation: ...")],
)

# 3) 주 에이전트는 동일한 block을 읽어 사용자 질의 처리
# (테스트 단계에서는 shadow 모드로 비교)
```

운영 시점에서 중요한 건 다음이다.

- `sleep_agent`와 `primary`가 공유하는 블록이 단일화되지 않으면 충돌이 생긴다.
- `finish_rethink` 호출 조건이 없으면 반복 루프가 길어진다.
- 테스트에서는 반드시 기본값 출력 품질과 비용을 비교해야 한다.

## 15. 삼성 AI 포럼 2025를 내 시각으로 읽은 이유

삼성 AI 포럼 공식 보도에서 특히 인상적인 부분은 다음이다.

- **포럼 기간/규모:** 2025년 9월 15~16일, 9회차 행사. 
- **에이전트 전환 선언:** “Generative to Agentic AI” 프레임이 메인 주제.
- **연사 축:** 요슈아 벤지오, 조셉 곤잘레스, 스테파노 에르몬 등.
- **슬립타임 메시지:** 사용자-에이전트 상호작용 공백 시간 활용 추론·학습·계획.

이 메시지가 중요한 이유는 이렇다.

첫째, 한국 기업 환경에서 에이전트는 단발성 챗봇이 아니라 일상 속 도구로 들어가고 있다.
둘째, 대화는 일정 간격으로 끊기고 다시 시작되는 패턴이 많다.
셋째, 반복형 작업에서 비용이 가장 큰 곳이 바로 고객 대응, 사내 문서 질의, 디바이스 제어이다.

즉, 슬립타임 컴퓨트는 한국 시장에서 단지 논문 아이디어가 아니라, **운영 효율의 실전 패턴**이 될 수 있다.

특히 디바이스 중심 환경(스마트폰/웨어러블/홈 AI)에서는 “항상 온라인”보다 “항상 학습 가능한 오프라인”이 더 중요해진다. 사용자가 요청하지 않을 때도 제품이 메모리의 유용성을 높이는 동작을 할 수 있어야 실제 체감 성능이 오른다.

## 16. 한국형 실무 적용 체크리스트

내가 실제 팀에서 제안할 체크리스트를 여기에 옮겨 둔다.

1. **데이터 분리**
   - 로그(raw), 문서(raw), 정제 기억(summary) 분리 저장
2. **질의 예측 인덱스 정의**
   - 반복 패턴(FAQ, 운영 규칙, 법무/재무 요약 등)을 태깅
3. **메모리 편집 승인 정책**
   - 자동 반영, 수동 리뷰, 점진 자동화 3단계를 둔다.
4. **슬립타임 빈도 설정**
   - 초반은 10~30분 단위, 점차 빈도 낮추기
5. **감사 로그 노출**
   - 사용자가 요청했을 때 “근거 메모리 블록” 조회 가능성 제공
6. **실험 설계**
   - 테스트타임 토큰/지연 감소, 오답률, 재질문율 동시 추적

이 과정을 거치면 기술이 화려해 보여도 운영 신뢰도를 지킬 수 있다.

---

## 참고 링크

- arXiv: [Sleep-time Compute: Beyond Inference Scaling at Test-time](https://arxiv.org/abs/2504.13171)
- Letta 공식 소개: [Sleep-time Compute](https://www.letta.com/blog/sleep-time-compute)
- Letta 코드 저장소: [letta-ai/sleep-time-compute](https://github.com/letta-ai/sleep-time-compute)
- 삼성 AI 포럼 2025 공식 보도: [삼성 뉴스룸](https://news.samsung.com/kr/%EC%82%BC%EC%84%B1%EC%A0%84%EC%9E%90-%EC%82%BC%EC%84%B1-ai-%ED%8F%AC%EB%9F%BC-2025-%EA%B0%9C%EC%B5%9C)

