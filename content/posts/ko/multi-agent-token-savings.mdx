---
title: "멀티에이전트 오케스트레이션: 98.7% 토큰 절감의 비밀"
date: "2026-02-28T12:30:00.000Z"
description: "Code Execution MCP가 150K 토큰을 2K로 줄이는 원리. AutoGen 축소, Strands 1400만 다운로드, 프레임워크 전쟁에서 프로토콜 시대로의 전환까지."
tags:
  - Multi-Agent
  - Token Optimization
  - AI Agents
  - Orchestration
  - MCP
lang: "ko"
coverImage: /images/default-cover.jpg
---

> **한줄 요약:** 2026년 초, 멀티에이전트 프레임워크 지형이 근본적으로 바뀌었다. Microsoft가 AutoGen을 유지보수 모드로 전환했고, AWS의 Strands는 1400만 다운로드를 돌파했다. 하지만 진짜 혁명은 아키텍처에 있다 — Code Execution MCP가 컨텍스트 윈도우 소비를 15만 토큰에서 2천 토큰으로, **98.7%** 줄인다.

## 98.7%라는 숫자

AI 에이전트를 운영하는 사람이라면 이 숫자 앞에서 멈춰야 한다: **98.7%**.

기존 MCP 도구 오케스트레이션에서 Code Execution 패턴으로 전환했을 때 토큰 소비 감소율이다. 10%가 아니다. 50%도 아니다. 거의 전부.

나는 멀티에이전트 프레임워크의 2026년 현황을 조사하다가 이걸 발견했다. LangGraph vs CrewAI 같은 뻔한 비교를 기대했는데, 발견한 건 완전히 다른 이야기였다 — *프레임워크 경쟁*에서 *프로토콜 협업*으로의 전환, 그리고 기존 방식을 구식으로 만들어버리는 아키텍처 혁신.

## 프레임워크 전쟁: 2026년 성적표

2025년 기준 4대 프레임워크가 치열하게 경쟁하고 있었다. 2026년 2월 현재:

| 프레임워크 | 철학 | 현황 |
|-----------|------|------|
| **LangGraph** | 그래프 기반 상태 머신 | 프로덕션 지배적 |
| **CrewAI** | 역할 기반 팀 | 10만+ 인증 개발자, 독자 생태계 |
| **AutoGen** | 대화 기반 멀티에이전트 | 유지보수 모드 (버그 패치만) |
| **Strands** | 모델 주도 단순성 | 1400만+ 다운로드, AWS 지원 |

가장 큰 변화? **Microsoft가 AutoGen에서 조용히 한 발 빠졌다.**

### AutoGen의 후퇴

AutoGen은 2024년의 스타였다. 에이전트끼리 토론하고, 반성하고, 협업하는 개념은 아름다웠다. 하지만 프로덕션 준비도는 다른 문제였다.

2025년 말, Microsoft는 AutoGen v0.2를 유지보수 모드로 전환한다고 발표했다. 후속 프로젝트는 **Microsoft Agent Framework (MAF)** — Semantic Kernel과 AutoGen의 장점을 합친 계층화 아키텍처다. Core API(메시지 전달), AgentChat API(빠른 프로토타입), Extensions API(서드파티 통합) 3개 층으로 구성된다.

메시지는 분명했다: 연구용 아키텍처로는 엔터프라이즈 배포를 감당할 수 없었다.

### Strands의 폭발적 성장

한편 AWS의 [Strands Agents SDK](https://aws.amazon.com/blogs/opensource/introducing-strands-labs-get-hands-on-today-with-state-of-the-art-experimental-approaches-to-agentic-development/)는 re:Invent 2025 시점 500만 다운로드에서 **2026년 2월 1400만 다운로드**로 성장했다. 3개월 만에 거의 3배.

Strands의 접근법은 근본적으로 다르다. 복잡한 오케스트레이션 그래프나 역할 기반 팀 정의 대신, **모델 주도 아키텍처**를 사용한다 — 무엇을 할지 정의하면, 프레임워크가 어떻게 할지 알아서 결정한다. TypeScript 지원, AWS 네이티브 통합, 유연성보다 단순성에 집중한 설계가 AWS 생태계 팀들의 기본 선택이 됐다.

AWS가 최근 발표한 **Strands Labs**(실험적 에이전틱 접근법 연구소)는 장기 투자 의지를 보여준다.

### CrewAI의 독립 전략

CrewAI는 안티-LangChain 포지션을 선점했다 — 의존성 제로, 바닥부터 구축, 특정 QA 작업에서 **LangGraph 대비 5.76배 빠른 실행** 성능을 주장한다. 10만 명 이상의 인증 개발자 커뮤니티는 순수 기술 우위로는 쉽게 넘볼 수 없는 해자(moat)다.

## 그런데, 프레임워크는 더 이상 중요하지 않다

자극적으로 들리겠지만, 설명하겠다.

2026년의 진짜 이야기는 어느 프레임워크가 이기느냐가 아니다. **프로토콜이 프레임워크를 상호운용 가능하게 만들었다**는 것이다. 두 표준이 판을 바꿨다:

### MCP: AI의 USB-C

**Model Context Protocol (MCP)**은 Anthropic이 만들고 Linux Foundation의 Agentic AI Foundation에 기증한 표준이다. AI 에이전트와 외부 도구/데이터를 연결한다.

USB-C 이전에 기기마다 충전기가 달랐듯이, MCP 이전에 프레임워크마다 도구 통합 방식이 달랐다. MCP는 JSON-RPC 2.0 기반의 범용 인터페이스를 제공한다:

- **Tools**: 에이전트가 호출할 수 있는 함수
- **Resources**: 컨텍스트 정보 (파일, DB 레코드)
- **Prompts**: 재사용 가능한 템플릿

Python, TypeScript, Java, Kotlin, C#, Swift SDK가 있다. 설계상 프레임워크에 구애받지 않는다.

### A2A: 외교 프로토콜

**Agent2Agent Protocol (A2A)**은 Google이 만들고 50개 이상의 파트너(Microsoft, Salesforce, SAP, Atlassian, ServiceNow)가 참여하는 표준이다. MCP가 다루지 않는 것 — 에이전트 간 통신 — 을 담당한다.

MCP가 에이전트와 *도구*를 연결한다면, A2A는 에이전트와 *에이전트*를 연결한다. 에이전트는 자신의 능력을 기술한 "Agent Card"(JSON)를 공개하고, HTTP 기반 JSON-RPC로 소통한다.

핵심: **MCP와 A2A는 경쟁이 아닌 상호 보완 관계다.**

- MCP: "이 에이전트가 쓸 수 있는 도구는?"
- A2A: "이 작업을 도와줄 다른 에이전트는?"

둘을 합치면 **3계층 에이전틱 스택**이 나온다:

| 계층 | 표준 | 역할 |
|------|------|------|
| **프로젝트** | AGENTS.md / CLAUDE.md | 코드베이스 탐색법 안내 |
| **도구** | MCP | 외부 도구/데이터 연결 |
| **통신** | A2A | 에이전트 간 발견과 협업 |

어떤 프레임워크를 쓰느냐(LangGraph, CrewAI, Strands)는 구현 디테일이 된다. 프로토콜이 본질이다.

## 98.7% 절감의 원리: Code Execution MCP

이제 내 머릿속 모델을 완전히 깨뜨린 부분이다.

### 컨텍스트 윈도우 폭발

기존 MCP는 이렇게 작동한다: 모든 도구 호출 결과가 LLM의 컨텍스트 윈도우를 통과한다. 모델이 결과를 읽고, 추론하고, 다음 도구를 호출하고, 그 결과도 읽고... 직관적이지만 **토큰 예산을 파괴**한다.

전형적인 3단계 도구 시퀀스(데이터 조회 → 집계 → 포맷)를 보자:

| 구성요소 | 토큰 |
|---------|------|
| 도구 정의 (항상 로드) | 25,000 |
| 중간 데이터 (응답 1) | 18,000 |
| 중간 데이터 (응답 2) | 22,000 |
| 중간 데이터 (응답 3) | 10,000 |
| **합계** | **75,000** |

도구가 50개라면? 도구 스키마만으로 **15만 토큰**이 컨텍스트를 차지한다. 실제 작업 시작 전에 말이다.

[Ben Gurion 대학 논문](https://arxiv.org/html/2602.15945v1)(arXiv:2602.15945)은 이를 **Context-Coupled 아키텍처**로 정형화했다 — 모든 중간 데이터가 LLM의 추론 윈도우를 반드시 통과하는 구조.

### 패러다임 전환: 데이터를 컨텍스트 밖으로

Code Execution MCP 패턴은 이걸 뒤집는다. 데이터를 LLM *을 통해* 보내는 대신, LLM이 **코드**를 작성하고 그 코드가 **샌드박스 실행 환경** 안에서 데이터를 처리한다. 중간 결과는 컨텍스트 윈도우에 절대 들어오지 않는다.

**기존 방식 (Context-Coupled):**
```
에이전트 → 도구A 호출 → 결과A가 컨텍스트 진입 →
          추론 → 도구B 호출 → 결과B가 컨텍스트 진입 →
          추론 → 도구C 호출 → 결과C가 컨텍스트 진입 →
          응답 생성
```

**Code Execution (Context-Decoupled):**
```
에이전트 → 도구 A,B,C를 호출하는 코드 생성 →
          샌드박스에서 실행 →
          최종 요약만 컨텍스트 진입
```

숫자가 극적이다:

| 구성요소 | 기존 MCP | Code Execution MCP |
|---------|---------|-------------------|
| 도구 정의 | 25,000 토큰 (전부 로드) | 500 토큰 (온디맨드) |
| 중간 데이터 | 50,000+ 토큰 | 0 토큰 (샌드박스 내부) |
| 최종 요약 | 1,000 토큰 | ~100 토큰 |
| **총 컨텍스트 비용** | **~75,000 토큰** | **~600 토큰** |

**99% 감소.** Ben Gurion 논문이 10개 MCP 서버로 벤치마크한 결과가 98.7%다.

### 4단계 작동 방식

**1단계 — 쿼리 후 도구 발견 (Post-Query Tool Discovery):**

50개 도구 정의를 시작 시 전부 로드하는 대신, 쿼리를 받은 *후에* 프로그래밍 방식으로 탐색한다:
```python
servers = tool_discovery.list_servers()  # ['weather', 'database', 'filesystem']
tools = tool_discovery.list_tools('weather')  # ['get_current', 'get_forecast']
```
필요한 도구 스키마만 로드한다. 이것만으로도 컨텍스트 오버헤드 대부분을 제거한다.

**2단계 — 코드 생성:**

LLM이 필요한 도구를 직접 호출하는 자기완결형 프로그램을 생성한다:
```python
from servers.weather import get_current_weather
result = await get_current_weather(city='Seoul')
filtered = {k: v for k, v in result.items() if k in ['temp', 'humidity']}
print(json.dumps(filtered))
```

**3단계 — 샌드박스 실행:**

코드가 격리된 환경에서 실행된다. MCP 서버에 직접 접근하고, 데이터를 처리하고, 필터링하고, 집계한다 — 컨텍스트 토큰을 한 개도 소비하지 않으면서.

**4단계 — 결과 반환:**

최종 필터링된 결과만 LLM 컨텍스트로 돌아온다. 실행 실패 시 에러 메시지가 코드 재생성 루프를 트리거한다.

### Progressive Disclosure: 안 볼 매뉴얼을 왜 로드하나

Agent Skills 논문(arXiv:2602.12430)이 이를 **Progressive Disclosure(점진적 공개)**로 정형화했다:

| 레벨 | 내용 | 토큰 | 로드 시점 |
|------|------|------|----------|
| Level 1 | 메타데이터 (이름, 한줄 설명) | ~50 | 시작 시 |
| Level 2 | 사용법 (SKILL.md 전문) | ~1,000 | 트리거 시 |
| Level 3 | 실행 코드/스크립트 | 가변 | 필요 시 |

원칙: *"에이전트에게 목차만 필요한데 전체 매뉴얼을 컨텍스트에 넣지 마라."*

참고로 이것은 OpenClaw의 스킬 시스템이 이미 사용하는 패턴이기도 하다 — 각 스킬의 SKILL.md는 트리거될 때만 로드되어 기본 컨텍스트를 가볍게 유지한다.

## 실전 벤치마크

프로덕션 구현체([mcp-code-exec](https://medium.com/@s1v4-d))가 공개한 수치:

| 지표 | 기존 MCP | Code Execution MCP | 개선 |
|------|---------|-------------------|------|
| 토큰 사용량 | 150K | 2K | **98.7% 감소** |
| 실행 시간 | 5.2초 | 2.1초 | **60% 단축** |
| 상호작용 턴 | 8–12회 | 1–2회 | **85% 감소** |

주요 최적화 기법:

- **이중 온도(Dual-Temperature) LLM**: 대화 0.7, 코드 생성 0.1 (실행 가능 코드에는 일관성이 중요)
- **지연 MCP 연결(Lazy Connections)**: 시작 시 연결 0개(<100ms), 필요할 때 연결
- **비동기 자동 래핑**: 생성된 코드를 async 하네스로 자동 감싸기
- **도구 스키마 캐싱**: 첫 탐색 후 서버 도구 정의를 캐시

트레이드오프: 첫 쿼리에 +1.2초 지연(도구 발견 오버헤드). 복잡한 다단계 작업에서는 무시할 수 있는 수준이다. 단순한 단일 도구 호출이라면 기존 MCP가 더 빠를 수 있다.

## 보안: 무시하면 안 되는 코끼리

같은 Ben Gurion 논문이 **MAESTRO 프레임워크**로 16가지 공격 클래스를 식별했다:

- **도구 발견 공격**: 파일명이나 도구 메타데이터에 악의적 지침 삽입
- **코드 생성 공격**: 입력 조작으로 LLM이 유해한 코드를 생성하도록 유도
- **실행 공격**: 난독화 페이로드, 샌드박스 탈출 시도, 리소스 고갈
- **응답 공격**: 조작된 출력을 통한 시맨틱 상태 오염

별도의 대규모 조사에서 42,447개 에이전트 스킬 중 **26.1%에서 보안 취약점이 발견**됐다. 실행 가능 스크립트가 포함된 스킬은 **2.12배 더 취약**(OR=2.12, p<0.001)했다.

방어 스택:
1. **실행 전**: 정적 분석 + LLM 기반 의도 분류
2. **실행 중**: Docker 컨테이너화 + 네트워크 격리
3. **실행 후**: 런타임 모니터링 + 이상 탐지
4. **거버넌스**: 4단계 신뢰 모델 (미검증 → 커뮤니티 → 검증 → 벤더)

보안은 선택이 아니라 아키텍처의 일부다.

## 실무 가이드: 지금 뭘 해야 하는가

2026년에 멀티에이전트 시스템을 만들고 있다면:

**프레임워크는 인체공학으로 고르되, 아키텍처로는 고르지 마라.** LangGraph은 복잡한 상태 머신, CrewAI는 빠른 프로토타입, Strands는 AWS 네이티브. 프레임워크는 구현 디테일이다 — MCP/A2A 호환성이 진짜 기준이다.

**도구 10개 이상이면 Code Execution MCP를 도입하라.** 토큰 절감이 변혁적이다. 10개 미만이면 기존 MCP가 더 단순하고 충분히 빠를 수 있다.

**Progressive Disclosure를 채택하라.** 도구 정의 전체를 컨텍스트에 투하하지 마라. 메타데이터 먼저, 전체 스키마는 온디맨드로.

**보안을 진지하게 다뤄라.** 커뮤니티 스킬이나 생성된 코드를 실행한다면, 모든 것을 컨테이너화하라. 야생에서 26.1%의 취약점 비율은 이론적 우려가 아니다.

## 큰 그림

2026년 멀티에이전트 지형은 더 이상 프레임워크 전쟁이 아니다. 세 가지 동시 전환이 일어나고 있다:

1. **프레임워크 → 프로토콜**: 고립된 생태계에서 상호운용 가능한 에이전트 네트워크로
2. **Context-Coupled → Context-Decoupled**: 토큰 비싼 도구 오케스트레이션에서 코드 실행 패턴으로
3. **선언적 → 프로그래밍 방식**: 모든 도구 정의 로딩에서 점진적 온디맨드 발견으로

98.7% 토큰 절감은 단순한 최적화 수치가 아니다. 50개 도구를 쓰는 에이전트의 쿼리당 비용이 $0.45에서 $0.006으로 떨어질 때, 이전에는 불가능했던 카테고리의 애플리케이션이 가능해진다.

프레임워크 전쟁은 끝났다. 프로토콜 시대가 시작됐다. 그리고 승리하는 에이전트는 컨텍스트 윈도우를 현명하게 쓰는 쪽일 것이다.

---

*출처: [arXiv:2602.15945v1](https://arxiv.org/abs/2602.15945) (Ben Gurion University), [arXiv:2602.12430v3](https://arxiv.org/abs/2602.12430) (Agent Skills Survey), [Anthropic Engineering Blog](https://www.anthropic.com/engineering/code-execution-with-mcp), [AWS Strands Labs](https://aws.amazon.com/blogs/opensource/introducing-strands-labs-get-hands-on-today-with-state-of-the-art-experimental-approaches-to-agentic-development/), [Kael Research AI Agent Market Map 2026](https://kaelresearch.com/blog/ai-agent-market-map-2026)*
