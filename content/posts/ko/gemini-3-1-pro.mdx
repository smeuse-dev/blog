---
title: "구글 제미나이 3.1 프로 출시 — 벤치마크 숫자들이 심상치 않다"
date: "2026-02-20T11:30:00.000Z"
description: "ARC-AGI-2 77.1%로 전작의 2.5배, Humanity's Last Exam에서 Claude Opus 4.6·GPT-5.2 제치고 1위, 가격은 그대로. 오늘 나온 제미나이 3.1 프로의 벤치마크를 파헤친다."
tags: ["제미나이", "구글", "AI모델", "벤치마크", "LLM", "딥마인드"]
series: "AI 심층 분석"
seriesPart: 3
---

<Figure
  src="/images/posts/gemini-3-1/gemini-3-1-pro-hero.jpg"
  alt="구글 제미나이 3.1 프로 발표"
  caption="제미나이 3.1 프로: Gemini 앱, API, Vertex AI, NotebookLM, Gemini CLI 등 오늘부터 순차 롤아웃"
  credit="Google DeepMind"
  creditUrl="https://blog.google/intl/ko-kr/products/gemini-3-1-pro-kr/"
  priority={true}
/>

## 오늘 나왔다

구글이 2026년 2월 19일, 제미나이 3.1 프로를 출시했다.

타이밍은 예상 범위 안이다. AI 모델 경쟁이 압축되고 있다. Anthropic이 Claude를 업그레이드했고, OpenAI가 GPT-5.2 Codex를 출시했다. 구글이 가만히 있을 이유가 없었다.

그런데 3.1 프로는 단순한 맞대응 이상이다. 벤치마크 수치들이 점진적 개선이 아닌 **질적 도약**에 가깝다.

---

## 벤치마크 수치들

### ARC-AGI-2: 77.1%

가장 주목할 숫자다. ARC-AGI-2는 AI가 **완전히 새로운 논리 패턴**을 풀어내는 능력을 측정한다. 훈련 데이터에서 외웠을 가능성이 없는, 처음 보는 문제들이다. 현재 가장 공정한 추론 능력 측정 방식 중 하나로 꼽힌다.

| 모델 | ARC-AGI-2 |
|------|-----------|
| **제미나이 3.1 프로** | **77.1%** |
| 제미나이 3 프로 | 31.1% |
| Claude Opus 4.6 | ~45% |
| GPT-5.2 | ~52% |

31.1%에서 77.1%로. 한 버전 만에 2.5배. 이건 조금 더 나아진 게 아니다.

### Humanity's Last Exam (HLE)

수학, 과학, 인문학 전반에 걸친 박사급 문제들로 구성된 벤치마크. "현재 AI로는 풀기 어렵게 설계됐다"는 학문적 목적으로 만들어졌다. 여기서 3.1 프로가 **Claude Opus 4.6과 GPT-5.2를 모두 앞섰다**.

### GPQA Diamond

대학원급 과학 추론 문제. 동일한 결과 — GPT-5.2와 Claude Opus 4.6보다 높은 점수.

### APEX-Agents 리더보드: 1위

Mercor CEO 브렌던 푸디의 발표가 가장 실용적인 신호일 수 있다. APEX-Agents는 학문적 문제가 아닌 **실제 업무 태스크** 수행 능력을 측정하는 벤치마크다.

> "제미나이 3.1 프로가 APEX-Agents 리더보드 1위에 올랐습니다. 에이전트들이 실제 지식 업무에서 얼마나 빠르게 발전하고 있는지를 보여줍니다." — 브렌던 푸디, Mercor CEO

---

## 무엇을 위해 만들어졌나

구글이 명시적으로 강조한 건 **"단순한 답으로 충분하지 않은 작업"**을 위한 모델이라는 점이다.

발표에서 보여준 데모들:

**코드 기반 애니메이션** — 텍스트 프롬프트 하나로 웹사이트용 SVG 애니메이션을 생성. 픽셀이 아닌 순수 코드 출력이라 어떤 크기에서도 선명하고 파일 크기가 작다.

**복잡한 시스템 통합** — 국제우주정거장(ISS)의 궤도를 실시간 시각화하는 항공우주 대시보드를 처음부터 구축. 공개 텔레메트리 스트림을 스스로 파악해 연결했다.

**인터랙티브 3D 디자인** — 떼까마귀 군집 비행(murmuration) 3D 시뮬레이션. 손 트래킹으로 조작 가능하고, 새들의 움직임에 따라 변화하는 음악까지 생성했다.

**문학 → 코드 번역** — 에밀리 브론테의 *폭풍의 언덕*을 기반으로 한 포트폴리오 사이트 요청 시, 소설 요약이 아니라 작품의 분위기를 코드로 표현했다.

---

## 스펙 & 가격

| | 제미나이 3.1 프로 |
|-|-----------------|
| 컨텍스트 윈도우 | 1,000,000 토큰 |
| 최대 출력 | 64,000 토큰 |
| 입력 가격 | $2.50 / M 토큰 |
| 출력 가격 | $15.00 / M 토큰 |
| 추론 방식 | Dynamic Thinking (기본 활성) |

가격이 **3 프로와 동일하다**. 이 점이 중요하다. 더 나은 성능을 같은 가격에 — 이것이 모델 경쟁이 만들어내는 결과다.

---

## 어디서 쓸 수 있나

오늘부터 순차 롤아웃:

- **Gemini 앱** — 일반 사용자(무료), 유료 플랜은 더 높은 사용량
- **Gemini API / Google AI Studio** — 개발자 프리뷰
- **Vertex AI** — 기업 사용자
- **NotebookLM** — AI Pro·Ultra 플랜 유료 사용자
- **Gemini CLI** — 커맨드라인 환경
- **Google Antigravity** — 에이전틱 개발 플랫폼
- **Android Studio** — 모바일 개발자

---

## AI 모델 경쟁 구도에서의 의미

이번 발표에서 구글이 강조한 것: 3.1 프로는 지난주 업데이트된 **Gemini 3 Deep Think**의 기반이 되는 핵심 지능이라는 점.

구글·Anthropic·OpenAI에서 공통적으로 보이는 패턴이 있다. **추론 계층**(Deep Think, Extended Thinking, o3 스타일)과 **핵심 지능 계층**(Pro, Opus, GPT-5.2)을 분리하는 것. 전자는 최상단 한계를 밀어올리고, 후자는 일상적인 워크호스 역할을 한다 — 단, 후자의 기준선도 빠르게 올라가고 있다.

6개월 전 "확장 추론 모드"가 필요했던 작업들이, 이제 표준 추론으로 처리되기 시작하고 있다. ARC-AGI-2 77.1%가 그 증거다.

---

## 솔직한 주의사항

AI 회사 간 벤치마크 비교는 신뢰하기 어렵다. 각 회사가 자신들에게 유리한 평가를 선택한다. ARC-AGI-2는 상대적으로 독립적이고 HLE는 게임핑을 방지하도록 설계됐지만, 독립적 재현엔 시간이 필요하다.

가장 신뢰할 만한 신호는 학술 문제 벤치마크보다 APEX-Agents 1위 — 실무 태스크 수행 능력 측정이기 때문이다.

그리고 현재는 **프리뷰** 상태다. 정식 출시는 아직 아니어서 프로덕션 배포는 기다려야 한다.

지금 당장 테스트해보고 싶다면 Google AI Studio에서 가능하다.

---

*출처: [구글 블로그 KR](https://blog.google/intl/ko-kr/products/gemini-3-1-pro-kr/) · [TechCrunch](https://techcrunch.com/2026/02/19/googles-new-gemini-pro-model-has-record-benchmark-scores-again/) · [조선비즈](https://biz.chosun.com/it-science/ict/2026/02/20/JKAALERSNRDP3J47KJMRFFD2AI/) · [테크42](https://www.tech42.co.kr/%EA%B5%AC%EA%B8%80-%EC%A0%9C%EB%AF%B8%EB%82%98%EC%9D%B4-3-1-%ED%94%84%EB%A1%9C-%EC%B6%9C%EC%8B%9C-%EC%A3%BC%EC%9A%94-%EB%B2%A4%EC%B9%98%EB%A7%88%ED%81%AC-1%EC%9C%84/)*
